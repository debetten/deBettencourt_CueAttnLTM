{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import pandas as pd\n",
    "from matplotlib import rc\n",
    "import scikits.bootstrap as bootstrap  \n",
    "from scipy.stats.stats import spearmanr, ttest_1samp, zscore, ttest_ind, ttest_rel\n",
    "from necessary_analysis_scripts import resampling_statistics,  run_stats_onetail, run_stats_twotail\n",
    "from necessary_analysis_scripts import prettify_plot, calculate_aprime, load_data\n",
    "from necessary_analysis_scripts import bin_classify, plot_classify\n",
    "from necessary_analysis_scripts import run_nonparam_stats_onetail\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from datetime import date\n",
    "from datetime import date\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "import mne\n",
    "import pickle\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot within jupyter notebooks\n",
    "%matplotlib inline \n",
    "\n",
    "#tab completion for files\n",
    "%config IPCompleter.greedy=True \n",
    "\n",
    "#supress scientific notation\n",
    "np.set_printoptions(suppress=True) \n",
    "\n",
    "#font defaults\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "rc('text', usetex=False)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "if os.path.isfile(\"/Library/Fonts/HelveticaNeue-Light.ttf\"): \n",
    "    prop = fm.FontProperties(fname=\"/Library/Fonts/HelveticaNeue-Light.ttf\",size=24)\n",
    "else:\n",
    "    prop = fm.FontProperties(size=24)\n",
    "\n",
    "#color defaults\n",
    "col_cue = (60/255.,83/255.,164/255.)\n",
    "col_uncue = (219/255.,11/255.,132/255.)\n",
    "\n",
    "col_cue_acc = [6/255.,0,128/255.]\n",
    "col_cue_inacc = [157/255.,153/255.,255/255.]\n",
    "col_uncue_acc = [128/255.,13/255.,86/255.]\n",
    "col_uncue_inacc = [255/255.,163/255.,221/255.]\n",
    "\n",
    "b=[11/255.,0/255.,255/255.]\n",
    "m=[220/255.,11/255.,144/255.]\n",
    "g=[0/255.,220/255.,104/255.]\n",
    "o=[245/255.,128/255.,37/155.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate classification information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nits=100\n",
    "t0 = np.arange(-300,1501,10)\n",
    "t = np.arange(-300,1501)\n",
    "nt = np.size(t0)\n",
    "tw = 100\n",
    "clf = LogisticRegression(C=1,solver='liblinear',multi_class='ovr')\n",
    "\n",
    "t0 = np.arange(-300,1501,10)\n",
    "nt = np.size(t0)\n",
    "iter_freqs = [\n",
    "    (4,7),\n",
    "    (8,12),\n",
    "    (13,16),\n",
    "    (16,20),\n",
    "    (20,25),\n",
    "    (25,30)\n",
    "]\n",
    "\n",
    "alpha = [(8,12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eeg data files\n",
    "project_name = 'rtPreStim02' #project directory \n",
    "#project_dir = '/Users/megan/Documents/projects/' + project_name + '/' #project directory \n",
    "project_dir = '/Volumes/Megabyte/' + project_name + '/' #project directory \n",
    "os.chdir(project_dir)\n",
    "\n",
    "#behavior files\n",
    "exp_name = 'expt2'\n",
    "exp_dir = '/Users/megan/Dropbox/writing/articles/2019_rtPreStim/' + exp_name + '/'\n",
    "eeg_dir = '/Users/megan/Dropbox/writing/articles/2019_rtPreStim/expt2_eeg/'\n",
    "\n",
    "#subject files\n",
    "subj_name = ['0626171_rtPreStim02','0627171_rtPreStim02','0628171_rtPreStim02',\n",
    "             '0629171_rtPreStim02','0710171_rtPreStim02','0719171_rtPreStim02',\n",
    "             '0720171_rtPreStim02','0725171_rtPreStim02','0803171_rtPreStim02',\n",
    "             '0809171_rtPreStim02','0816171_rtPreStim02','0821171_rtPreStim02',\n",
    "             '0824171_rtPreStim02','0828171_rtPreStim02','0829171_rtPreStim02',\n",
    "             '0830171_rtPreStim02','0830172_rtPreStim02','0901171_rtPreStim02',\n",
    "             '0904171_rtPreStim02','0906171_rtPreStim02','0907171_rtPreStim02',\n",
    "             '0908171_rtPreStim02','0915171_rtPreStim02','0919171_rtPreStim02',\n",
    "             '0922171_rtPreStim02','1005171_rtPreStim02','1010171_rtPreStim02',\n",
    "             '1011171_rtPreStim02','1013171_rtPreStim02','1102171_rtPreStim02']\n",
    "\n",
    "#calculate total number of subjects\n",
    "nsubj = np.size(subj_name)\n",
    "print ('total # subjects: %d' %(nsubj))\n",
    "\n",
    "nb = 16              #number of blocks\n",
    "nt_wm_perblock = 24  #number of wm trials per block\n",
    "nt_ltm_perblock = 60 #number of ltm trials per block  \n",
    "nt_wm = nb*nt_wm_perblock #total number of encoding trials         \n",
    "nt_ltm = nb*nt_ltm_perblock #total number of retrieval trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_wm = {}\n",
    "dat_ltm = {}\n",
    "for isubj in range(nsubj):\n",
    "    dat_wm[isubj] = pd.read_csv(exp_dir + subj_name[isubj] +'_wmlog.csv')\n",
    "    dat_ltm[isubj] = pd.read_csv(exp_dir + subj_name[isubj] +'_ltmlog.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load artifact information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cue_wmorder_noarf = np.ones((nsubj,nt_wm))\n",
    "for isubj in range(nsubj):\n",
    "    dir_eeg = project_dir + 'subjects/' + subj_name[isubj] + '/data/eeg/'\n",
    "    \n",
    "    #cue time period\n",
    "    fn=dir_eeg + subj_name[isubj] + '_EEG_SEG_CLEAN.mat'\n",
    "    if os.path.isfile(fn):\n",
    "        mat_contents = sio.loadmat(fn,struct_as_record=False,squeeze_me=True)\n",
    "        erp = mat_contents['erp']\n",
    "        idx_eeg_arf = np.where(erp.arf.artifactIndCleaned==1)[0]\n",
    "        cue_wmorder_noarf[isubj,idx_eeg_arf] = 0\n",
    "    else:\n",
    "        print('ERROR: no file exists for subject: ', subj_name[isubj])     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cue_wmresperr = np.zeros((nsubj,nt_wm))\n",
    "cue_ltmresperr = np.zeros((nsubj,nt_wm))\n",
    "cue_ltmh = np.zeros((nsubj,nt_wm))\n",
    "for isubj in range(nsubj):\n",
    "    for ib in range(nb):        \n",
    "        #identify ltm trials for this block (ranges from 0-60, total 60 trials)\n",
    "        itrials_block = np.where(dat_ltm[isubj].block==ib)[0]\n",
    "        \n",
    "        #identify which of those trials were probed (ranges from 0-60, total 24 trials)\n",
    "        itrials_probe = np.where(np.logical_or(dat_ltm[isubj].ltmTrialsOldValidCued[itrials_block]==1,dat_ltm[isubj].ltmTrialsOldInvalidTested[itrials_block]==1))[0]\n",
    "\n",
    "        #save the trial number for this block (ranges from 0-384 for wm, 0-960 for ltm)\n",
    "        itrials_wm = ib*nt_wm_perblock+np.arange(nt_wm_perblock)\n",
    "        itrials_ltm = ib*nt_ltm_perblock+np.arange(nt_ltm_perblock)\n",
    "\n",
    "        #select the memory performance variables for trials from this block (probed trials only)\n",
    "        respdiff_wm = np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm])\n",
    "        respdiff_ltm = np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm])[itrials_probe]\n",
    "        h_ltm = np.ravel(dat_ltm[isubj].ltmrating[itrials_ltm])[itrials_probe]==1\n",
    "        \n",
    "        #find the wm trial num for the tested trials\n",
    "        itrials_ltm_wmtrialnum = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])[itrials_probe]\n",
    "\n",
    "        #loop through all trials in this block\n",
    "        for it in range(nt_wm_perblock):\n",
    "            \n",
    "            #find this trial order\n",
    "            it_wmorder = np.where(itrials_ltm_wmtrialnum==it)[0][0]\n",
    "            \n",
    "            cue_wmresperr[isubj,itrials_wm[it]] = respdiff_wm[it]\n",
    "            cue_ltmresperr[isubj,itrials_wm[it]] = respdiff_ltm[it_wmorder]\n",
    "            cue_ltmh[isubj,itrials_wm[it]] = h_ltm[it_wmorder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_classify_probcoef(X,y,clf,t=np.arange(-300,1501),t0 = np.arange(-300,1501,10),tw=100,nits=100,nbins=3,iclass=1,shuff=True,scaler=True,trainprop=.5):\n",
    "    \n",
    "    acc_bin = np.empty((nits,np.size(t0)))\n",
    "    coef_bin = np.empty((nits,np.size(t0),np.size(np.unique(y)),np.shape(X)[1]))\n",
    "    proba_bin = np.empty((nits,np.size(t0),np.size(np.unique(y)),np.size(np.unique(y))))\n",
    "    acc_bin_shuff = np.empty((nits,np.size(t0)))\n",
    "    \n",
    "    cv = StratifiedShuffleSplit(n_splits=nits)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    nlabels=np.size(np.unique(y))\n",
    "    nmin = np.min([np.sum(y==i) for i in np.arange(0,nlabels)])\n",
    "    nperbin = int(np.floor(nmin/nbins))\n",
    "    nmin = nperbin*nbins\n",
    "    for it_counter in range(nits):\n",
    "\n",
    "        y_bin = np.sort(np.tile((np.unique(y)),nbins))\n",
    "        \n",
    "        #balance sizes \n",
    "        X_bin = np.zeros((np.size(y_bin),np.shape(X)[1],np.shape(X)[2]))\n",
    "\n",
    "        counter = 0\n",
    "        for i,ilabel in enumerate(np.unique(y)):\n",
    "            temp=np.where(y==ilabel)[0]\n",
    "            np.random.shuffle(temp)\n",
    "            temp = temp[:nmin] #downsample\n",
    "            if nbins != 2:\n",
    "                temp_binned_labels = np.reshape(temp,(nbins,nperbin))\n",
    "            else:\n",
    "                if trainprop==.5:\n",
    "                    temp_binned_labels = np.reshape(temp,(nbins,nperbin))\n",
    "                else:\n",
    "                    temp_binned_labels = {}\n",
    "                    i = int(np.floor(trainprop*nmin))\n",
    "                    temp_binned_labels[0] = temp[:i]\n",
    "                    temp_binned_labels[1] = temp[i:]\n",
    "            for ibin in range(nbins):\n",
    "                X_bin[counter] = np.mean(X[temp_binned_labels[ibin]],axis=0)\n",
    "                counter=counter+1\n",
    "        \n",
    "        if nbins==2:\n",
    "            itrain = np.sort(np.arange(0,nlabels*nbins,nbins))\n",
    "            itest = np.arange(1,nlabels*nbins,nbins)            \n",
    "        elif nbins==3:\n",
    "            itrain = np.sort(np.append(np.arange(0,nlabels*nbins,nbins),np.arange(1,nlabels*nbins,nbins)))\n",
    "            itest = np.arange(2,nlabels*nbins,nbins)\n",
    "        elif nbins==4:\n",
    "            itrain = np.sort(np.append(np.append(np.arange(0,nlabels*nbins,nbins),np.arange(1,nlabels*nbins,nbins)),np.arange(2,nlabels*nbins,nbins)))\n",
    "            itest = np.arange(3,nlabels*nbins,nbins)\n",
    "        elif nbins==6: \n",
    "            itrain = np.sort(np.append(np.append(np.append(np.arange(0,nlabels*nbins,nbins),np.arange(1,nlabels*nbins,nbins)),np.arange(2,nlabels*nbins,nbins)),np.arange(3,nlabels*nbins,nbins)))\n",
    "            itest = np.sort(np.append(np.arange(4,nlabels*nbins,nbins),np.arange(5,nlabels*nbins,nbins)))\n",
    "        else:\n",
    "            print(\"only coded for nbins 2, 3, 4 or 6\")\n",
    "        \n",
    "        for n,tstart in enumerate(t0):\n",
    "            #find the indices of the appropriate time window\n",
    "            idx = np.where(np.logical_and(t>=tstart,t<(tstart+tw)))[0]\n",
    "            X_train = np.mean(X_bin[itrain][:,:,idx],axis=2)\n",
    "            X_test = np.mean(X_bin[itest][:,:,idx],axis=2)\n",
    "            \n",
    "            #standard scaler\n",
    "            scaler.fit(X_train)\n",
    "            scaler.transform(X_train)\n",
    "            scaler.transform(X_test)\n",
    "            \n",
    "            y_train = y_bin[itrain]\n",
    "            y_test = y_bin[itest]\n",
    "            if shuff:\n",
    "                y_train_shuff = y_bin[itrain][np.random.permutation(np.size(y_train))]\n",
    "                y_test_shuff = y_bin[itest][np.random.permutation(np.size(y_test))]\n",
    "\n",
    "            #train model\n",
    "            clf.fit(X_train,y_train)\n",
    "            \n",
    "            #test model\n",
    "            acc_bin[it_counter,n] = clf.score(X_test,y_test)\n",
    "            \n",
    "            #coef\n",
    "            #print(clf.coef_)\n",
    "            #print(np.shape(clf.coef_))\n",
    "            coef_bin[it_counter,n] = clf.coef_\n",
    "            \n",
    "            #proba\n",
    "            proba_bin[it_counter,n] = clf.predict_proba(X_test)\n",
    "            if shuff:\n",
    "                clf.fit(X_train,y_train_shuff)\n",
    "                acc_bin_shuff[it_counter,n] = clf.score(X_test,y_test_shuff)    \n",
    "\n",
    "    return acc_bin, coef_bin, proba_bin, acc_bin_shuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we predict trial-by-trial fluctuations of long-term memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nits=2\n",
    "acc_sustattn = np.zeros((nsubj,nits,nt))\n",
    "acc_sustattn_shuff = copy.deepcopy(acc_ltmresperr_cuev)\n",
    "\n",
    "for isubj in np.arange(nsubj):\n",
    "    print(isubj)\n",
    "    \n",
    "    #load erp\n",
    "    dir_eeg = project_dir + 'subjects/' + subj_name[isubj] + '/data/eeg/'\n",
    "    fn=dir_eeg + subj_name[isubj] + '_EEG_SEG_CLEAN.mat'\n",
    "    mat_contents = sio.loadmat(fn,struct_as_record=False,squeeze_me=True)\n",
    "    erp = mat_contents['erp']\n",
    "\n",
    "    #calculate alpha power\n",
    "    info = mne.create_info(erp.chanLabels[:30].tolist(),1000,'eeg')\n",
    "    epochs = mne.EpochsArray(erp.trial.baselined[erp.arf.artifactIndCleaned==0,:30],info=info,tmin=-1.1,baseline=None)\n",
    "    \n",
    "    counter=0\n",
    "    for fmin, fmax in iter_freqs:\n",
    "        raw_bp = epochs.copy()\n",
    "        raw_bp.filter(fmin,fmax,n_jobs=1,l_trans_bandwidth=1,h_trans_bandwidth=1)\n",
    "        raw_bp.apply_hilbert(envelope=True)\n",
    "        raw_bp.crop(-.3,1.5)\n",
    "\n",
    "        if counter == 0:\n",
    "            eegs_allfreq = raw_bp._data/np.mean(raw_bp._data[:,:,:300])\n",
    "        else:\n",
    "            eegs_allfreq = np.append(eegs_allfreq,raw_bp._data/np.mean(raw_bp._data[:,:,:300]),axis=1)\n",
    "\n",
    "        counter = counter+1\n",
    "    \n",
    "    #classify mne data \n",
    "    w=np.floor(np.ravel(dat_wm[isubj].cueposbin[cue_wmorder_noarf[isubj]==1]/2))\n",
    "    x=np.abs(cue_ltmresperr[isubj][cue_wmorder_noarf[isubj]==1])\n",
    "    cuev = (dat_wm[isubj].cuevalid==1)[cue_wmorder_noarf[isubj]==1]\n",
    "    y = [np.median(x[w==i]) for i in range(4)] \n",
    "    y_cuev = [np.median(x[np.logical_and(w==i,cuev)]) for i in range(4)] \n",
    "    y_cuei = [np.median(x[np.logical_and(w==i,cuev==0)]) for i in range(4)] \n",
    "    z = np.zeros(np.shape(w))\n",
    "    for i in range(4):\n",
    "        z[np.logical_and(w==i,x<y[i])] = 0\n",
    "    for i in range(4):\n",
    "        z[np.logical_and(w==i,x>=y[i])] = 1\n",
    "    print(z)\n",
    "    labels = z\n",
    "    \n",
    "    acc_sustattn[isubj],_,_,acc_sustattn_shuff[isubj] = bin_classify_probcoef(eegs_allfreq,labels,clf,nits=nits,tw=tw,t0=t0,nbins=2)\n",
    "    \n",
    "    df = pd.DataFrame(acc_sustattn[isubj])\n",
    "    df.columns = t0\n",
    "    df.to_csv(eeg_dir + subj_name[isubj] + \"_sustattn_\" + date.today().strftime('%Y%m%d') + \".csv\",index=True,header=True)\n",
    "\n",
    "    df = pd.DataFrame(acc_sustattn_shuff[isubj])\n",
    "    df.columns = t0\n",
    "    df.to_csv(eeg_dir + subj_name[isubj] + \"_sustattn_\" + date.today().strftime('%Y%m%d') + \".csv\",index=True,header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics\n",
    "temp_p = np.empty(nt)\n",
    "for iit in range(nt):\n",
    "    temp_p[iit],_ = run_stats_onetail(np.mean(acc_ltmresperr_cuev*100,axis=1)[:,iit],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.fill_between(t0,np.mean(np.mean(acc_sustattn*100,axis=1),axis=0)-np.std(np.mean(acc_sustattn*100,axis=1),axis=0)/np.sqrt(nsubj),\n",
    "                 np.mean(np.mean(acc_sustattn*100,axis=1),axis=0)+np.std(np.mean(acc_sustattn*100,axis=1),axis=0)/np.sqrt(nsubj),\n",
    "                color='blue',alpha=.25)\n",
    "ax.plot(t0,np.mean(np.mean(acc_sustattn*100,axis=0),axis=0),color='blue')\n",
    "ax.fill_between(t0,np.mean(np.mean(acc_sustattn_shuff*100,axis=1),axis=0)-np.std(np.mean(acc_sustattn_shuff*100,axis=1),axis=0)/np.sqrt(nsubj),\n",
    "                np.mean(np.mean(acc_sustattn_shuff*100,axis=1),axis=0)+np.std(np.mean(acc_sustattn_shuff*100,axis=1),axis=0)/np.sqrt(nsubj),\n",
    "               color='k',alpha=.25)\n",
    "ax.plot(t0,np.mean(np.mean(acc_sustattn_shuff*100,axis=0),axis=0),color='k',alpha=.5)\n",
    "thr=.05\n",
    "#plt.scatter(t0[temp_p<thr],np.ones(nt)[temp_p<thr]*46,marker='s',color='k')\n",
    "#plt.scatter(t0[temp_p>(1-thr)],np.ones(nt)[temp_p>(1-thr)]*46,marker='s',color='k')\n",
    "prettify_plot(ax,xlim=[-300,1500],ylim=[30,70],\n",
    "             xt=[-300,0,300,600,900,1200,1500],\n",
    "             xtl=[-300,0,300,600,900,1200,1500],\n",
    "             yt=[30,40,50,60,70],\n",
    "             ytl=[30,40,50,60,70],\n",
    "             xl='Time relative to cue (ms)',\n",
    "             yl='Classifier accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do long-term memory fluctuations reflect differences in spatial attention? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nits=1000\n",
    "t0 = np.arange(-300,1501,10)\n",
    "nt = np.size(t0)\n",
    "n = copy.deepcopy(nsubj)\n",
    "s = copy.deepcopy(subj_name)\n",
    "iter_freqs = [\n",
    "    (8,12),\n",
    "]\n",
    "acc_cuepos_traccinacc_testinacc = np.zeros((n,nits,nt))\n",
    "acc_cuepos_traccinacc_testinacc_shuff = copy.deepcopy(acc_cuepos_inacctrials)\n",
    "acc_cuepos_traccinacc_testacc = np.zeros((n,nits,nt))\n",
    "acc_cuepos_traccinacc_testacc_shuff = copy.deepcopy(acc_cuepos_inacctrials)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for isubj in np.arange(n):\n",
    "    print(isubj)\n",
    "    \n",
    "    #load erp\n",
    "    dir_eeg = project_dir + 'subjects/' + subj_name[isubj] + '/data/eeg/'\n",
    "    fn=dir_eeg + subj_name[isubj] + '_EEG_SEG_CLEAN.mat'\n",
    "    mat_contents = sio.loadmat(fn,struct_as_record=False,squeeze_me=True)\n",
    "    erp = mat_contents['erp']\n",
    "\n",
    "    #calculate alpha power\n",
    "    info = mne.create_info(erp.chanLabels[:30].tolist(),1000,'eeg')\n",
    "    epochs = mne.EpochsArray(erp.trial.baselined[erp.arf.artifactIndCleaned==0,:30],info=info,tmin=-1.1,baseline=None)\n",
    "    \n",
    "    counter=0\n",
    "    for fmin, fmax in iter_freqs:\n",
    "        raw_bp = epochs.copy()\n",
    "        raw_bp.filter(fmin,fmax,n_jobs=1,l_trans_bandwidth=1,h_trans_bandwidth=1)\n",
    "        #raw_bp.subtract_evoked()\n",
    "        raw_bp.apply_hilbert(envelope=True)\n",
    "        #mne.baseline.rescale(raw_bp._data,raw_bp.times, (None,0), mode='zscore',copy=False)\n",
    "        raw_bp.crop(-.3,1.5)\n",
    "\n",
    "        if counter == 0:\n",
    "            eegs_allfreq = raw_bp._data\n",
    "        else:\n",
    "            eegs_allfreq = np.append(eegs_allfreq,raw_bp._data,axis=1)\n",
    "\n",
    "        counter = counter+1\n",
    "    \n",
    "    #classify mne data \n",
    "    w=np.floor(np.ravel(dat_wm[isubj].cueposbin[cue_wmorder_noarf[isubj]==1]/2))\n",
    "    x=np.abs(cue_ltmresperr[isubj][cue_wmorder_noarf[isubj]==1])\n",
    "    cuev = (dat_wm[isubj].cuevalid==1)[cue_wmorder_noarf[isubj]==1]\n",
    "    y_cuev = [np.median(x[np.logical_and(w==i,cuev)]) for i in range(4)] \n",
    "    z = np.zeros(np.sum(cuev))\n",
    "    for i in range(4):\n",
    "        z[np.logical_and(w[cuev==1]==i,x[cuev==1]<y_cuev[i])] = 0\n",
    "    for i in range(4):\n",
    "        z[np.logical_and(w[cuev==1]==i,x[cuev==1]>=y_cuev[i])] = 1\n",
    "    print(z)\n",
    "    \n",
    "    #\n",
    "    labels_acc = w[cuev==1][z==0]\n",
    "    eegs_acc = eegs_allfreq[cuev==1][z==0]\n",
    "    labels_inacc = w[cuev==1][z==1]\n",
    "    eegs_inacc = eegs_allfreq[cuev==1][z==1]\n",
    "    \n",
    "    nbins=2\n",
    "    nlabels_acc=np.size(np.unique(labels_acc))\n",
    "    nmin_acc = np.min([np.sum(labels_acc==i) for i in np.arange(0,nlabels_acc)])\n",
    "    nperbin_acc = int(np.floor(nmin_acc/nbins))\n",
    "    nlabels_inacc=np.size(np.unique(labels_inacc))\n",
    "    nmin_inacc = np.min([np.sum(labels_inacc==i) for i in np.arange(0,nlabels_inacc)])\n",
    "    nperbin_inacc = int(np.floor(nmin_inacc/nbins))\n",
    "    nperbin = np.min([nperbin_acc,nperbin_inacc])\n",
    "    nmin = nperbin*nbins\n",
    "    \n",
    "    labels_acc_bin = np.sort(np.tile((np.unique(labels_acc)),nbins))\n",
    "    labels_inacc_bin = np.sort(np.tile((np.unique(labels_inacc)),nbins))\n",
    "        \n",
    "    for it_counter in range(nits):\n",
    "\n",
    "        #balance sizes \n",
    "        eegs_acc_bin = np.zeros((np.size(labels_acc_bin),np.shape(eegs_acc)[1],np.shape(eegs_acc)[2]))\n",
    "        eegs_inacc_bin = np.zeros((np.size(labels_inacc_bin),np.shape(eegs_inacc)[1],np.shape(eegs_inacc)[2]))\n",
    "\n",
    "        #bin trials\n",
    "        counter = 0\n",
    "        for i,ilabel in enumerate(np.unique(labels_acc)):\n",
    "            temp=np.where(labels_acc==ilabel)[0]\n",
    "            np.random.shuffle(temp)\n",
    "            temp = temp[:nmin] #downsample\n",
    "            temp_binned_labels = np.reshape(temp,(nbins,nperbin))\n",
    "            \n",
    "            for ibin in range(nbins):\n",
    "                eegs_acc_bin[counter] = np.mean(eegs_acc[temp_binned_labels[ibin]],axis=0)\n",
    "                counter=counter+1\n",
    "        \n",
    "        counter = 0\n",
    "        for i,ilabel in enumerate(np.unique(labels_inacc)):\n",
    "            temp=np.where(labels_inacc==ilabel)[0]\n",
    "            np.random.shuffle(temp)\n",
    "            temp = temp[:nmin] #downsample\n",
    "            temp_binned_labels = np.reshape(temp,(nbins,nperbin))\n",
    "            \n",
    "            for ibin in range(nbins):\n",
    "                eegs_inacc_bin[counter] = np.mean(eegs_inacc[temp_binned_labels[ibin]],axis=0)\n",
    "                counter=counter+1\n",
    "        \n",
    "        eegs_train = np.mean(np.append(eegs_acc_bin[np.arange(0,counter,nbins)][np.newaxis],eegs_inacc_bin[np.arange(0,counter,nbins)][np.newaxis],axis=0),axis=0)\n",
    "        labels_train = labels_acc_bin[np.arange(0,counter,nbins)]\n",
    "        \n",
    "        eegs_test_acc = eegs_acc_bin[np.arange(1,counter,nbins)]\n",
    "        eegs_test_inacc = eegs_inacc_bin[np.arange(1,counter,nbins)]\n",
    "        labels_test_acc = labels_acc_bin[np.arange(1,counter,nbins)]\n",
    "        labels_test_inacc = labels_inacc_bin[np.arange(1,counter,nbins)]\n",
    "    \n",
    "        for n,tstart in enumerate(t0):\n",
    "            #find the indices of the appropriate time window\n",
    "            idx = np.where(np.logical_and(t>=tstart,t<(tstart+tw)))[0]\n",
    "            X_train = np.mean(eegs_train[:,:,idx],axis=2)\n",
    "            X_test_acc = np.mean(eegs_test_acc[:,:,idx],axis=2)\n",
    "            X_test_inacc = np.mean(eegs_test_inacc[:,:,idx],axis=2)\n",
    "            \n",
    "            #standard scaler\n",
    "            scaler.fit(X_train)\n",
    "            scaler.transform(X_train)\n",
    "            scaler.transform(X_test_acc)\n",
    "            scaler.transform(X_test_inacc)\n",
    "\n",
    "            #train model\n",
    "            clf.fit(X_train,labels_train)\n",
    "            \n",
    "            #test model\n",
    "            acc_cuepos_traccinacc_testacc[isubj,it_counter,n] = clf.score(X_test_acc,labels_test_acc)\n",
    "            acc_cuepos_traccinacc_testinacc[isubj,it_counter,n] = clf.score(X_test_inacc,labels_test_inacc)\n",
    "    \n",
    "    df = pd.DataFrame(acc_cuepos_traccinacc_testinacc[isubj])\n",
    "    df.columns = t0\n",
    "    df.to_csv(eeg_dir + subj_name[isubj] + \"_acc_cuepos_traccinacc_testinacc_\" + date.today().strftime('%Y%m%d') + \".csv\",index=True,header=True)\n",
    "\n",
    "    df = pd.DataFrame(acc_cuepos_traccinacc_testacc[isubj])\n",
    "    df.columns = t0\n",
    "    df.to_csv(eeg_dir + subj_name[isubj] + \"_acc_cuepos_traccinacc_testacc_\" + date.today().strftime('%Y%m%d') + \".csv\",index=True,header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_p_acc = np.empty(nt)\n",
    "for iit in range(nt):\n",
    "    temp_p_acc[iit],_ = run_stats_onetail(np.mean(acc_cuepos_traccinacc_testacc,axis=1)[:,iit],.25)\n",
    "    \n",
    "temp_p_inacc = np.empty(nt)\n",
    "for iit in range(nt):\n",
    "    temp_p_inacc[iit],_ = run_stats_onetail(np.mean(acc_cuepos_traccinacc_testinacc,axis=1)[:,iit],.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_p = np.empty(nt)\n",
    "for iit in range(nt):\n",
    "    temp_p[iit],_ = run_stats_onetail(np.mean(acc_cuepos_traccinacc_testacc,axis=1)[:,iit],np.mean(acc_cuepos_traccinacc_testinacc,axis=1)[:,iit])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.mean(np.mean(acc_cuepos_traccinacc_testacc,axis=1),axis=0)\n",
    "ye=np.std(np.mean(acc_cuepos_traccinacc_testacc,axis=1),axis=0)/np.sqrt(nsubj_cue)\n",
    "plt.fill_between(t0,y-ye,y+ye,alpha=.5)\n",
    "plt.plot(t0,y)\n",
    "y=np.mean(np.mean(acc_cuepos_traccinacc_testinacc,axis=1),axis=0)\n",
    "ye=np.std(np.mean(acc_cuepos_traccinacc_testinacc,axis=1),axis=0)/np.sqrt(nsubj_cue)\n",
    "plt.fill_between(t0,y-ye,y+ye,alpha=.5)\n",
    "plt.plot(t0,y)\n",
    "plt.scatter(t0[temp_p<.025],.5*np.ones(np.sum(temp_p<.025)),color='k')\n",
    "plt.scatter(t0[temp_p_acc<.05],.49*np.ones(np.sum(temp_p_acc<.05)),color='b')\n",
    "plt.scatter(t0[temp_p_inacc<.05],.48*np.ones(np.sum(temp_p_inacc<.05)),color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WM vs LTM labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nits=1000\n",
    "t0 = np.arange(-300,1501,10)\n",
    "nt = np.size(t0)\n",
    "n = copy.deepcopy(nsubj)\n",
    "s = copy.deepcopy(subj_name)\n",
    "nlabels = np.zeros((nsubj),dtype=int)\n",
    "nconsistent = np.zeros((nsubj))\n",
    "nconsistent_shuffle = np.zeros((nsubj,nits))\n",
    "n_within2deg = np.zeros((nsubj))\n",
    "thr_subj = np.zeros((nsubj))\n",
    "for isubj in np.arange(nsubj):\n",
    "    print(isubj)\n",
    "    \n",
    "    #classify mne data \n",
    "    #labels_mne = np.floor(np.ravel(dat_wm_cue[isubj].cueposbin[cue_wmorder_noarf[isbj]==1])/2)\n",
    "    w=np.floor(np.ravel(dat_wm[isubj].cueposbin[cue_wmorder_noarf[isubj]==1]/2))\n",
    "    x=np.abs(cue_ltmresperr[isubj][cue_wmorder_noarf[isubj]==1])\n",
    "    cuev = (dat_wm[isubj].cuevalid==1)[cue_wmorder_noarf[isubj]==1]\n",
    "    y = [np.median(x[w==i]) for i in range(4)] \n",
    "    y_cuev = [np.median(x[np.logical_and(w==i,cuev)]) for i in range(4)] \n",
    "    y_cuei = [np.median(x[np.logical_and(w==i,cuev==0)]) for i in range(4)] \n",
    "    z = np.zeros(np.shape(w))\n",
    "    for i in range(4):\n",
    "        z[np.logical_and(w==i,x<y[i])] = 0\n",
    "        #z[np.logical_and(np.logical_and(w==i,cuev==1),x<y_cuev[i])] = 0\n",
    "        #z[np.logical_and(np.logical_and(w==i,cuev==0),x<y_cuei[i])] = 0\n",
    "    for i in range(4):\n",
    "        z[np.logical_and(w==i,x>=y[i])] = 1\n",
    "        #z[np.logical_and(np.logical_and(w==i,cuev==1),x>=y_cuev[i])] = 1\n",
    "        #z[np.logical_and(np.logical_and(w==i,cuev==0),x>=y_cuei[i])] = 1\n",
    "    #print(z)\n",
    "    labels = z\n",
    "    x_ltm = copy.deepcopy(x)\n",
    "    z_ltm = copy.deepcopy(z)\n",
    "    \n",
    "    #classify mne data \n",
    "    #labels_mne = np.floor(np.ravel(dat_wm_cue[isubj].cueposbin[cue_wmorder_noarf[isbj]==1])/2)\n",
    "    w=np.floor(np.ravel(dat_wm[isubj].cueposbin[cue_wmorder_noarf[isubj]==1]/2))\n",
    "    x=np.abs(cue_wmresperr[isubj][cue_wmorder_noarf[isubj]==1])\n",
    "    cuev = (dat_wm[isubj].cuevalid==1)[cue_wmorder_noarf[isubj]==1]\n",
    "    y = [np.median(x[w==i]) for i in range(4)] \n",
    "    y_cuev = [np.median(x[np.logical_and(w==i,cuev)]) for i in range(4)] \n",
    "    y_cuei = [np.median(x[np.logical_and(w==i,cuev==0)]) for i in range(4)] \n",
    "    z = np.zeros(np.shape(w))\n",
    "    \n",
    "    for i in range(4):\n",
    "        z[np.logical_and(w==i,x<y[i])] = 0\n",
    "        #z[np.logical_and(np.logical_and(w==i,cuev==1),x<y_cuev[i])] = 0\n",
    "        #z[np.logical_and(np.logical_and(w==i,cuev==0),x<y_cuei[i])] = 0\n",
    "    for i in range(4):\n",
    "        z[np.logical_and(w==i,x>=y[i])] = 1\n",
    "        #z[np.logical_and(np.logical_and(w==i,cuev==1),x>=y_cuev[i])] = 1\n",
    "        #z[np.logical_and(np.logical_and(w==i,cuev==0),x>=y_cuei[i])] = 1\n",
    "    #print(z)\n",
    "    thr_wm = np.zeros(np.shape(w))\n",
    "    for ii in range(np.size(w)):\n",
    "        thr_wm[ii] = y[int(w[ii])]\n",
    "    n_within2deg[isubj] = np.sum(np.abs(x-thr_wm)<2)\n",
    "    labels_wm = z\n",
    "    thr_subj[isubj] = np.mean(y)\n",
    "    \n",
    "    nlabels[isubj] = np.size((labels_wm-labels))\n",
    "    nconsistent[isubj] = np.sum((labels_wm==labels))\n",
    "    \n",
    "    for iit in range(nits):\n",
    "        nconsistent_shuffle[isubj,iit] = np.sum((labels_wm[np.random.permutation(nlabels[isubj])]==labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_subj[isubj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(nconsistent/nlabels))\n",
    "print(np.std(nconsistent/nlabels))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
