{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rc\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import scikits.bootstrap as bootstrap\n",
    "from necessary_analysis_scripts import prettify_plot, bar_witherror_anddots\n",
    "from necessary_analysis_scripts import calculate_aprime, resampling_statistics, test_normality, run_stats\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_1samp\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "import scipy.stats as stats\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot within jupyter notebooks\n",
    "%matplotlib inline \n",
    "\n",
    "#tab completion for files\n",
    "%config IPCompleter.greedy=True \n",
    "\n",
    "#supress scientific notation\n",
    "np.set_printoptions(suppress=True) \n",
    "\n",
    "#font defaults\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "rc('text', usetex=False)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name_1a = 'expt1a'\n",
    "exp_name_1b = 'expt1b'\n",
    "exp_name_2 = 'expt2'\n",
    "exp_name_3a = 'expt3a'\n",
    "exp_name_3b = 'expt3b'\n",
    "\n",
    "#expdir\n",
    "exp_dir_1a = '../../' + exp_name_1a + '/'\n",
    "exp_dir_1b = '../../' + exp_name_1b + '/'\n",
    "exp_dir_2 = '../../' + exp_name_2 + '/'\n",
    "exp_dir_3a = '../../' + exp_name_3a + '/'\n",
    "exp_dir_3b = '../../' + exp_name_3b + '/'\n",
    "\n",
    "#project details\n",
    "nb = 16                     #number of blocks\n",
    "nt_wm_perblock = 24         #number of working memory trials per block\n",
    "nt_ltm_perblock = 60        #number of long-term memory trials per block\n",
    "nt_wm = nb*nt_wm_perblock   #total number of working memory trials\n",
    "nt_ltm = nb*nt_ltm_perblock #total number of long-term memory trials\n",
    "\n",
    "#statistics\n",
    "n_its = 100000              #number of iterations for statistics     \n",
    "\n",
    "#binning analysis\n",
    "nbins = 8\n",
    "prop_downsamp = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "24\n",
      "30\n",
      "24\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "subj_name_1a = ['0419171_rtPreStim01','0419172_rtPreStim01','0421171_rtPreStim01',\n",
    "             '0421172_rtPreStim01','0421173_rtPreStim01','0424171_rtPreStim01',\n",
    "             '0424172_rtPreStim01','0428171_rtPreStim01','0428172_rtPreStim01',\n",
    "             '0501171_rtPreStim01','0501173_rtPreStim01','0503171_rtPreStim01',\n",
    "             '0503172_rtPreStim01','0503173_rtPreStim01','0505171_rtPreStim01',\n",
    "             '0505172_rtPreStim01','0505175_rtPreStim01','0508171_rtPreStim01',\n",
    "             '0508172_rtPreStim01','0508173_rtPreStim01','0515171_rtPreStim01',\n",
    "             '0522171_rtPreStim01','0526171_rtPreStim01']\n",
    "nsubj_1a = np.size(subj_name_1a)\n",
    "print(nsubj_1a)\n",
    "\n",
    "subj_name_1b = ['0809181_rtPreStim08','0809182_rtPreStim08','0810181_rtPreStim08',\n",
    "             '0810182_rtPreStim08','0813181_rtPreStim08','0813182_rtPreStim08',\n",
    "             '0814181_rtPreStim08','0814182_rtPreStim08','0815181_rtPreStim08',\n",
    "             '0815182_rtPreStim08','0815183_rtPreStim08','0815184_rtPreStim08',\n",
    "             '0816182_rtPreStim08','0817181_rtPreStim08','0820181_rtPreStim08',\n",
    "             '0822181_rtPreStim08','0824181_rtPreStim08','0827181_rtPreStim08',\n",
    "             '0827183_rtPreStim08','0827184_rtPreStim08','0827185_rtPreStim08',\n",
    "             '0827186_rtPreStim08','0827187_rtPreStim08','0828181_rtPreStim08']\n",
    "nsubj_1b = np.size(subj_name_1b)\n",
    "print(nsubj_1b)\n",
    "\n",
    "subj_name_2 = ['0626171_rtPreStim02','0627171_rtPreStim02','0628171_rtPreStim02',\n",
    "             '0629171_rtPreStim02','0710171_rtPreStim02','0719171_rtPreStim02',\n",
    "             '0720171_rtPreStim02','0725171_rtPreStim02','0803171_rtPreStim02',\n",
    "             '0809171_rtPreStim02','0816171_rtPreStim02','0821171_rtPreStim02',\n",
    "             '0824171_rtPreStim02','0828171_rtPreStim02','0829171_rtPreStim02',\n",
    "             '0830171_rtPreStim02','0830172_rtPreStim02','0901171_rtPreStim02',\n",
    "             '0904171_rtPreStim02','0906171_rtPreStim02','0907171_rtPreStim02',\n",
    "             '0908171_rtPreStim02','0915171_rtPreStim02','0919171_rtPreStim02',\n",
    "             '0922171_rtPreStim02','1005171_rtPreStim02','1010171_rtPreStim02',\n",
    "             '1011171_rtPreStim02','1013171_rtPreStim02','1102171_rtPreStim02']\n",
    "nsubj_2 = np.size(subj_name_2)\n",
    "print(nsubj_2)\n",
    "\n",
    "subj_name_3a = ['0223181_rtPreStim05','0223182_rtPreStim05','0223183_rtPreStim05',\n",
    "             '0225181_rtPreStim05','0226181_rtPreStim05','0226182_rtPreStim05',\n",
    "             '0227181_rtPreStim05','0227182_rtPreStim05','0227183_rtPreStim05',\n",
    "             '0227184_rtPreStim05','0227185_rtPreStim05','0227186_rtPreStim05',\n",
    "             '0227187_rtPreStim05','0227188_rtPreStim05','0228181_rtPreStim05',\n",
    "             '0228182_rtPreStim05','0301181_rtPreStim05','0301182_rtPreStim05',\n",
    "             '0301183_rtPreStim05','0301184_rtPreStim05','0301185_rtPreStim05',\n",
    "             '0302181_rtPreStim05','0302182_rtPreStim05','0531181_rtPreStim05']\n",
    "\n",
    "nsubj_3a = np.size(subj_name_3a)\n",
    "print(nsubj_3a)\n",
    "\n",
    "subj_name_3b = ['0307181_rtPreStim06','0307182_rtPreStim06','0402181_rtPreStim06',\n",
    "            '0402183_rtPreStim06','0402184_rtPreStim06','0402185_rtPreStim06',\n",
    "            '0402186_rtPreStim06','0402187_rtPreStim06','0402188_rtPreStim06',\n",
    "            '0402189_rtPreStim06','0404181_rtPreStim06','0404182_rtPreStim06',\n",
    "            '0404183_rtPreStim06','0404184_rtPreStim06','0404185_rtPreStim06',\n",
    "            '0404186_rtPreStim06','0404187_rtPreStim06','0404188_rtPreStim06',\n",
    "            '0406181_rtPreStim06','0406182_rtPreStim06','0406183_rtPreStim06',\n",
    "            '0406184_rtPreStim06','0406185_rtPreStim06','0406186_rtPreStim06',\n",
    "            '0406188_rtPreStim06','0406189_rtPreStim06'] #'0406187_rtPreStim06' - CHECK FOR ZEROS\n",
    "nsubj_3b = np.size(subj_name_3b)\n",
    "print(nsubj_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# subjects = 127\n"
     ]
    }
   ],
   "source": [
    "#load files\n",
    "dat_wm_1a = {}\n",
    "dat_ltm_1a = {}\n",
    "for isubj in range(nsubj_1a):\n",
    "    dat_wm_1a[isubj] = pd.read_csv(exp_dir_1a + subj_name_1a[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_1a[isubj] = pd.read_csv(exp_dir_1a + subj_name_1a[isubj] +'_ltmlog.csv')\n",
    "dat_wm_1b = {}\n",
    "dat_ltm_1b = {}\n",
    "for isubj in range(nsubj_1b):\n",
    "    dat_wm_1b[isubj] = pd.read_csv(exp_dir_1b + subj_name_1b[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_1b[isubj] = pd.read_csv(exp_dir_1b + subj_name_1b[isubj] +'_ltmlog.csv')\n",
    "dat_wm_2 = {}\n",
    "dat_ltm_2 = {}\n",
    "for isubj in range(nsubj_2):\n",
    "    dat_wm_2[isubj] = pd.read_csv(exp_dir_2 + subj_name_2[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_2[isubj] = pd.read_csv(exp_dir_2 + subj_name_2[isubj] +'_ltmlog.csv')\n",
    "dat_wm_3a = {}\n",
    "dat_ltm_3a = {}\n",
    "for isubj in range(nsubj_3a):\n",
    "    dat_wm_3a[isubj] = pd.read_csv(exp_dir_3a + subj_name_3a[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_3a[isubj] = pd.read_csv(exp_dir_3a + subj_name_3a[isubj] +'_ltmlog.csv')\n",
    "dat_wm_3b = {}\n",
    "dat_ltm_3b = {}\n",
    "for isubj in range(nsubj_3b):\n",
    "    dat_wm_3b[isubj] = pd.read_csv(exp_dir_3b + subj_name_3b[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_3b[isubj] = pd.read_csv(exp_dir_3b + subj_name_3b[isubj] +'_ltmlog.csv')\n",
    "\n",
    "nsubj = nsubj_1a+nsubj_1b+nsubj_2+nsubj_3a+nsubj_3b\n",
    "print('# subjects = %d' %(nsubj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append\n",
    "dat_wm = {}\n",
    "dat_ltm = {}\n",
    "for isubj in range(nsubj):\n",
    "    if isubj<nsubj_1a:\n",
    "        dat_wm[isubj] = dat_wm_1a[isubj]\n",
    "        dat_ltm[isubj] = dat_ltm_1a[isubj]\n",
    "    elif isubj<(nsubj_1a+nsubj_1b):\n",
    "        dat_wm[isubj] = dat_wm_1b[isubj-nsubj_1a]\n",
    "        dat_ltm[isubj] = dat_ltm_1b[isubj-nsubj_1a]\n",
    "    elif isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "        dat_wm[isubj] = dat_wm_2[isubj-nsubj_1a-nsubj_1b]\n",
    "        dat_ltm[isubj] = dat_ltm_2[isubj-nsubj_1a-nsubj_1b]\n",
    "    elif isubj<(nsubj_1a+nsubj_1b+nsubj_2+nsubj_3a):\n",
    "        dat_wm[isubj] = dat_wm_3a[isubj-nsubj_1a-nsubj_1b-nsubj_2]\n",
    "        dat_ltm[isubj] = dat_ltm_3a[isubj-nsubj_1a-nsubj_1b-nsubj_2]\n",
    "    else:\n",
    "        dat_wm[isubj] = dat_wm_3b[isubj-nsubj_1a-nsubj_1b-nsubj_2-nsubj_3a]\n",
    "        dat_ltm[isubj] = dat_ltm_3b[isubj-nsubj_1a-nsubj_1b-nsubj_2-nsubj_3a] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0 completed 88%\t337 trials\n",
      "S1 completed 87%\t333 trials\n",
      "S2 completed 82%\t315 trials\n",
      "S3 completed 75%\t287 trials\n",
      "S4 completed 62%\t239 trials\n",
      "S5 completed 96%\t367 trials\n",
      "S6 completed 79%\t302 trials\n",
      "S7 completed 51%\t196 trials\n",
      "S8 completed 78%\t298 trials\n",
      "S9 completed 71%\t274 trials\n",
      "S10 completed 81%\t312 trials\n",
      "S11 completed 59%\t228 trials\n",
      "S12 completed 73%\t280 trials\n",
      "S13 completed 91%\t348 trials\n",
      "S14 completed 72%\t278 trials\n",
      "S15 completed 81%\t310 trials\n",
      "S16 completed 92%\t354 trials\n",
      "S17 completed 68%\t261 trials\n",
      "S18 completed 93%\t358 trials\n",
      "S19 completed 77%\t296 trials\n",
      "S20 completed 93%\t358 trials\n",
      "S21 completed 80%\t309 trials\n",
      "S22 completed 97%\t374 trials\n",
      "S23 completed 75%\t289 trials\n",
      "S24 completed 88%\t339 trials\n",
      "S25 completed 95%\t365 trials\n",
      "S26 completed 61%\t235 trials\n",
      "S27 completed 91%\t348 trials\n",
      "S28 completed 68%\t262 trials\n",
      "S29 completed 89%\t342 trials\n",
      "Avg completed 79.809028\t196-374\n",
      "306.46666666666664\n"
     ]
    }
   ],
   "source": [
    "proj_dir = '/Volumes/Megabyte/rtPreStim02/'\n",
    "\n",
    "#initialize all trials as 1 (meaning no artifacts)\n",
    "trialorder_wm_noarf = np.ones((nsubj_2,nt_wm)) \n",
    "trialorder_ltm_noarf = np.ones((nsubj_2,nt_ltm))\n",
    "\n",
    "for isubj in range(nsubj_2):\n",
    "    dir_eeg = proj_dir + 'subjects/' + subj_name_2[isubj] + '/data/eeg/'\n",
    "    if os.path.isfile(dir_eeg + subj_name_2[isubj] + '_EEG_SEG_CLEAN.mat'):\n",
    "        mat_contents = sio.loadmat(dir_eeg + subj_name_2[isubj] + '_EEG_SEG_CLEAN.mat',struct_as_record=False,squeeze_me=True)\n",
    "        erp = mat_contents['erp']\n",
    "        idx_eeg_arf = np.where(erp.arf.artifactIndCleaned==1)[0]\n",
    "        idx_noeeg_arf = np.where(erp.arf.artifactIndCleaned==0)[0]\n",
    "        n_trials_noarf = np.size(idx_noeeg_arf)\n",
    "        trialorder_wm_noarf[isubj,idx_eeg_arf] = 0\n",
    "    else:\n",
    "        print('ERROR: no file exists for subject: ', subj_name[isubj])\n",
    "        \n",
    "    print(\"S%i completed %d%%\\t%d trials\" %(isubj, np.round((np.sum(trialorder_wm_noarf[isubj]))/float(nt_wm),decimals=2)*100, np.sum(trialorder_wm_noarf[isubj])))\n",
    "\n",
    "print(\"Avg completed %f\\t%i-%i\" %(np.mean(np.mean(trialorder_wm_noarf==1,axis=1)*100),np.min(np.mean(trialorder_wm_noarf==1,axis=1))*384,np.max(np.mean(trialorder_wm_noarf==1,axis=1))*384))\n",
    "\n",
    "print(np.mean(np.sum(trialorder_wm_noarf==1,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialorder_ltm_noarf = np.zeros((nsubj_2,nt_ltm))\n",
    "for isubj in range(nsubj_2):\n",
    "    i = isubj+nsubj_1a+nsubj_1b\n",
    "    for ib in range(nb):\n",
    "        #identify probed ltmrieval trials for this block\n",
    "        itrials_wm_block = np.where(dat_wm[i].block==ib)[0]\n",
    "        itrials_ltm_block = np.where(dat_ltm[i].block==ib)[0]\n",
    "        \n",
    "        itrials_probe = np.where(np.logical_or(dat_ltm[i].ltmTrialsOldValidCued[itrials_ltm_block]==1,\n",
    "                                               dat_ltm[i].ltmTrialsOldInvalidTested[itrials_ltm_block]==1))[0]\n",
    "        itrials_cuedbutunprobed = np.where(dat_ltm[i].ltmTrialsOldInvalidCued[itrials_ltm_block]==1)[0]\n",
    "\n",
    "        #identify the wm trials for this block\n",
    "        #itrials_wm = ib*nt_wm_perblock+np.arange(nt_wm_perblock)\n",
    "        itrials_ltm = ib*nt_ltm_perblock+np.arange(nt_ltm_perblock)\n",
    "        \n",
    "        #identify the artifacts for this block, based on encoding\n",
    "        ib_wm_arf = trialorder_wm_noarf[isubj][itrials_wm_block]\n",
    "        \n",
    "        #loop through all trials in this block\n",
    "        temp_vec = np.zeros(24)\n",
    "        temp_vec_ltm = np.zeros(60)\n",
    "        temp_vec_ltm[:] = np.nan\n",
    "        for it in range(nt_wm_perblock):\n",
    "            \n",
    "            #identify the ltm trial for this wm trial in this block\n",
    "            it_ltm_wm = np.where(np.ravel(dat_ltm[i].ltmWMtrialNum[itrials_ltm_block]==it))[0]\n",
    "            temp_vec_ltm[it_ltm_wm] = ib_wm_arf[it]\n",
    "            #if np.size(it_ltm_wm)==1:\n",
    "            #    temp_vec_ltm[it_ltm_wm] = ib_wm_arf[it]\n",
    "            #else:\n",
    "            #    temp_vec_ltm[]\n",
    "            #if np.ravel(dat_wm[isubj].cuevalid[itrials_wm_block])[it]==0:\n",
    "            #    it_ltm_wm = np.where(np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm_block])[itrials_cuedbutunprobed]==it)[0]\n",
    "            #    temp_vec_ltm[it_ltm_wm] = (ib_wm_arf[it]==1)*1\n",
    "        trialorder_ltm_noarf[isubj][itrials_ltm] = temp_vec_ltm\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean wm and ltm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean response error:\n",
      "wm:\t 21.44 [19.87 23.27]\n",
      "ltm:\t 64.254 [61.64 66.68]\n",
      "Working memory: cued vs uncued\n",
      "Wilcoxon: t  0.0 p 1.3894515759554441e-22\n",
      "p:  1e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preallocate empty matrices\n",
    "resperr_wm_all = []\n",
    "resperr_ltm_all = []\n",
    "resperr_wm_mean = np.empty(nsubj)\n",
    "resperr_ltm_mean = np.empty(nsubj)\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "   \n",
    "    #wm\n",
    "    if isubj<(nsubj_1a+nsubj_1b):\n",
    "        resperr_wm = dat_wm[isubj]['wmresptestimgdiff']\n",
    "    elif isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "        resperr_wm = dat_wm[isubj]['wmresptestimgdiff'][trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1]\n",
    "    else:\n",
    "        resperr_wm = dat_wm[isubj]['wmresptestcolordiff']\n",
    "    resperr_wm_mean[isubj] = np.mean(np.abs(resperr_wm))\n",
    "    \n",
    "    #ltm\n",
    "    if isubj<(nsubj_1a+nsubj_1b):\n",
    "        resperr_ltm = dat_ltm[isubj]['ltmresptestimgdiff'][np.logical_or(dat_ltm[isubj]['ltmTrialsOldValidCued']==1,\n",
    "                                                                   dat_ltm[isubj]['ltmTrialsOldInvalidTested']==1)]\n",
    "    elif isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "        resperr_ltm = dat_ltm[isubj]['ltmresptestimgdiff'][np.logical_and(np.logical_or(dat_ltm[isubj]['ltmTrialsOldValidCued']==1,\n",
    "                                                                   dat_ltm[isubj]['ltmTrialsOldInvalidTested']==1),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)]\n",
    "\n",
    "    else:\n",
    "        resperr_ltm = dat_ltm[isubj]['ltmresptestimgdiff'][np.logical_or(dat_ltm[isubj]['ltmTrialsOldValidCued']==1,\n",
    "                                                                   dat_ltm[isubj]['ltmTrialsOldInvalidTested']==1)]\n",
    "\n",
    "    resperr_ltm_mean[isubj] = np.mean(np.abs(resperr_ltm))\n",
    "\n",
    "#statistics\n",
    "\n",
    "#confidence interval\n",
    "resperr_wm_CIs = bootstrap.ci(data=(resperr_wm_mean), statfunction=scipy.mean,n_samples=n_its)\n",
    "resperr_ltm_CIs = bootstrap.ci(data=(resperr_ltm_mean), statfunction=scipy.mean,n_samples=n_its)\n",
    "\n",
    "#print mean, CIs\n",
    "print(\"Mean response error:\")\n",
    "print(\"wm:\\t\", np.round(np.mean(resperr_wm_mean),decimals=2), np.round(resperr_wm_CIs,decimals=2))\n",
    "print(\"ltm:\\t\", np.round(np.mean(resperr_ltm_mean),decimals=3),np.round(resperr_ltm_CIs,decimals=2))\n",
    "\n",
    "#statistics\n",
    "print('Working memory: cued vs uncued')#wm vs ltm\n",
    "run_stats(resperr_ltm_mean,resperr_wm_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning analysis, all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate\n",
    "cuedvalidly_bin = np.zeros((nsubj,nbins))\n",
    "resperr_wm_bin = np.zeros((nsubj,nbins))\n",
    "resperr_ltm_bin = np.zeros((nsubj,nbins))\n",
    "cuedvalidly = []\n",
    "wmdiff = []\n",
    "ltmdiff = []\n",
    "\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    \n",
    "    #append all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuedvalidly.append(np.zeros(np.sum(trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)))\n",
    "        wmdiff.append(np.zeros(np.sum(trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)))\n",
    "        ltmdiff.append(np.zeros(np.sum(np.logical_and(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuedvalidly.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        wmdiff.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        ltmdiff.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3)),\n",
    "                                         trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = dat_wm[isubj].block==iblock\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        #reorder LTM difference according to wm encoding order\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuedvalidly[isubj][count] =(cuevalid[i])\n",
    "            wmdiff[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    temp_perc = (np.percentile(ltmdiff[isubj],np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "    \n",
    "    for i,iperc in enumerate(temp_perc[1:]):\n",
    "        cuedvalidly_bin[isubj,i]=np.mean(cuedvalidly[isubj][np.logical_and(ltmdiff[isubj]<iperc,ltmdiff[isubj]>temp_perc[i])])\n",
    "        resperr_wm_bin[isubj,i]=np.mean(wmdiff[isubj][np.logical_and(ltmdiff[isubj]<iperc,ltmdiff[isubj]>temp_perc[i])])\n",
    "        resperr_ltm_bin[isubj,i]= np.mean(ltmdiff[isubj][np.logical_and(ltmdiff[isubj]<iperc,ltmdiff[isubj]>temp_perc[i])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning analysis, cued items only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate\n",
    "cuedvalidly_cued_bin = np.zeros((nsubj,nbins))\n",
    "resperr_wm_cued_bin = np.zeros((nsubj,nbins))\n",
    "resperr_ltm_cued_bin = np.zeros((nsubj,nbins))\n",
    "wmdiff_cued = []\n",
    "ltmdiff_cued = []\n",
    "cuevalid_cued = []\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    \n",
    "    #append extra zeros for all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuevalid_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        wmdiff_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        ltmdiff_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuevalid_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        wmdiff_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        ltmdiff_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==1),trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==1),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==1)\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==1)\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuevalid_cued[isubj][count] =(cuevalid[i])\n",
    "            wmdiff_cued[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff_cued[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    temp_perc = (np.percentile(ltmdiff_cued[isubj],np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "    \n",
    "    for i,iperc in enumerate(temp_perc[1:]):\n",
    "        cuedvalidly_cued_bin[isubj,i]=np.mean(cuevalid_cued[isubj][np.logical_and(ltmdiff_cued[isubj]<iperc,ltmdiff_cued[isubj]>temp_perc[i])])\n",
    "        resperr_wm_cued_bin[isubj,i]=np.mean(wmdiff_cued[isubj][np.logical_and(ltmdiff_cued[isubj]<iperc,ltmdiff_cued[isubj]>temp_perc[i])])\n",
    "        resperr_ltm_cued_bin[isubj,i]= np.mean(ltmdiff_cued[isubj][np.logical_and(ltmdiff_cued[isubj]<iperc,ltmdiff_cued[isubj]>temp_perc[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning analysis, uncued items only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate\n",
    "cuedvalidly_uncued_bin = np.zeros((nsubj,nbins))\n",
    "resperr_wm_uncued_bin = np.zeros((nsubj,nbins))\n",
    "resperr_ltm_uncued_bin = np.zeros((nsubj,nbins))\n",
    "wmdiff_uncued = []\n",
    "ltmdiff_uncued = []\n",
    "cuevalid_uncued = []\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    \n",
    "    #append extra zeros for all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuevalid_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        wmdiff_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        ltmdiff_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuevalid_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        wmdiff_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        ltmdiff_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==0),trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==3),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==0)\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==3)\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuevalid_uncued[isubj][count] =(cuevalid[i])\n",
    "            wmdiff_uncued[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff_uncued[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    temp_perc = (np.percentile(ltmdiff_uncued[isubj],np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "    \n",
    "    for i,iperc in enumerate(temp_perc[1:]):\n",
    "        cuedvalidly_uncued_bin[isubj,i]=np.mean(cuevalid_uncued[isubj][np.logical_and(ltmdiff_uncued[isubj]<iperc,ltmdiff_uncued[isubj]>temp_perc[i])])\n",
    "        resperr_wm_uncued_bin[isubj,i]=np.mean(wmdiff_uncued[isubj][np.logical_and(ltmdiff_uncued[isubj]<iperc,ltmdiff_uncued[isubj]>temp_perc[i])])\n",
    "        resperr_ltm_uncued_bin[isubj,i]= np.mean(ltmdiff_uncued[isubj][np.logical_and(ltmdiff_uncued[isubj]<iperc,ltmdiff_uncued[isubj]>temp_perc[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate a measure of of the influence of sustained attention and spatial attention for each individual as the slope of each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sust = np.zeros((nsubj))\n",
    "m_sust_cued = np.zeros((nsubj))\n",
    "m_sust_uncued = np.zeros((nsubj))\n",
    "m_space = np.zeros((nsubj))\n",
    "for isubj in range(nsubj):\n",
    "    pfit1 = np.polyfit(np.arange(nbins),resperr_wm_cued_bin[isubj,:],1)\n",
    "    pfit2 = np.polyfit(np.arange(nbins),resperr_wm_uncued_bin[isubj,:],1)\n",
    "    m_sust_cued[isubj] = pfit1[0]\n",
    "    m_sust_uncued[isubj] = pfit2[0]\n",
    "    m_sust[isubj] = (pfit1[0]+pfit2[0])/2\n",
    "    \n",
    "    pfit = np.polyfit(np.arange(nbins),(1-cuedvalidly_bin[isubj,:]),1)\n",
    "    m_space[isubj] = pfit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats_for_ci_plot(x,y):\n",
    "    p, cov = np.polyfit(x, y, 1, cov=True)                     # parameters and covariance from of the fit of 1-D polynom.\n",
    "    y_model = np.polyval(p, x)                                   # model using the fit parameters; NOTE: parameters here are coefficients\n",
    "\n",
    "    # Statistics\n",
    "    n = y.size                                           # number of observations\n",
    "    m = p.size                                                 # number of parameters\n",
    "    dof = n - m                                                # degrees of freedom\n",
    "    t = stats.t.ppf(0.975, n - m)                              # used for CI and PI bands\n",
    "\n",
    "    # Estimates of Error in Data/Model\n",
    "    resid = y - y_model                           \n",
    "    chi2 = np.sum((resid / y_model)**2)                        # chi-squared; estimates error in data\n",
    "    chi2_red = chi2 / dof                                      # reduced chi-squared; measures goodness of fit\n",
    "    s_err = np.sqrt(np.sum(resid**2) / dof)                    # standard deviation of the error\n",
    "\n",
    "    x2 = np.linspace(np.min(x), np.max(x), 100)\n",
    "    y2 = equation(p, x2)\n",
    "\n",
    "    return t,s_err,n,x2,y2\n",
    "\n",
    "def plot_ci_manual(t, s_err, n, x, x2, y2, ax=None):\n",
    "    \"\"\"Return an axes of confidence bands using a simple approach.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    .. math:: \\left| \\: \\hat{\\mu}_{y|x0} - \\mu_{y|x0} \\: \\right| \\; \\leq \\; T_{n-2}^{.975} \\; \\hat{\\sigma} \\; \\sqrt{\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}}\n",
    "    .. math:: \\hat{\\sigma} = \\sqrt{\\sum_{i=1}^n{\\frac{(y_i-\\hat{y})^2}{n-2}}}\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Duarte.  \"Curve fitting,\" Jupyter Notebook.\n",
    "       http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/CurveFitting.ipynb\n",
    "\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ci = t * s_err * np.sqrt(1/n + (x2 - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "    ax.fill_between(x2, y2 + ci, y2 - ci, facecolor=\"k\", edgecolor=\"None\",alpha=.25)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'equation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-89a5cb2960d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresperr_ltm_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_err\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_stats_for_ci_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplot_ci_manual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_err\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#plot_ci_bootstrap(x, y, resid, ax=ax[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-95d0d4e6596f>\u001b[0m in \u001b[0;36mcalculate_stats_for_ci_plot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mequation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_err\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'equation' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x396 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(20,5.5))\n",
    "\n",
    "a=.1\n",
    "s=200\n",
    "\n",
    "x=m_sust\n",
    "y=resperr_ltm_mean\n",
    "ax[0].scatter(x,y,s=s,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "t,s_err,n,x2,y2 = calculate_stats_for_ci_plot(x,y)\n",
    "plot_ci_manual(t,s_err,n,x,x2,y2,ax=ax[0])\n",
    "#plot_ci_bootstrap(x, y, resid, ax=ax[0])\n",
    "pfit= np.polyfit(m_sust,resperr_ltm_mean,1)\n",
    "x = [np.min(m_sust),np.max(m_sust)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[0].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[0],xlim=[-5,10],ylim=[0,100],\n",
    "              xt=[-5,0,5,10],xtl=[-5,0,5,10],\n",
    "              yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "              xl=\"Sustained attention\",yl=\"Long-term memory\")\n",
    "\n",
    "\n",
    "\n",
    "x=m_space\n",
    "y=resperr_ltm_mean\n",
    "ax[1].scatter(x,y,s=s,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "t,s_err,n,x2,y2 = calculate_stats_for_ci_plot(x,y)\n",
    "plot_ci_manual(t,s_err,n,x,x2,y2,ax=ax[1])\n",
    "pfit= np.polyfit(m_space,resperr_ltm_mean,1)\n",
    "x = [np.min(m_space),np.max(m_space)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[1].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[1],xlim=[-.05,.1],ylim=[0,100],\n",
    "              xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "              yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "              xl=\"Spatial attention\",yl=\"Long-term memory\")\n",
    "\n",
    "x=m_space\n",
    "y=m_sust\n",
    "ax[2].scatter(x,y,s=s,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "t,s_err,n,x2,y2 = calculate_stats_for_ci_plot(x,y)\n",
    "plot_ci_manual(t,s_err,n,x,x2,y2,ax=ax[2])\n",
    "pfit= np.polyfit(m_space,m_sust,1)\n",
    "x = [np.min(m_space),np.max(m_space)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[2].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[2],xlim=[-.05,.1],ylim=[-5,10],\n",
    "             xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "             yt=[-5,0,5,10],ytl=[-5,0,5,10],\n",
    "             xl=\"Spatial attention\",yl=\"Sustained attention\")\n",
    "\n",
    "#plt.axis('scaled')\n",
    "#ax[0].set_aspect('scaled', adjustable='box')\n",
    "plt.subplots_adjust(wspace=.8)\n",
    "plt.subplots_adjust(hspace=.8)\n",
    "\n",
    "#fig_dir = fig_dir = '/Users/megan/Dropbox/conferences/202011_psych/figures/'\n",
    "#fig.savefig(fig_dir + 'figure6_individidff_scatterall_fit_example_1MdB.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spearmanr(m_sust,resperr_ltm_mean))\n",
    "print(spearmanr(m_space,resperr_ltm_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sust_mask = np.logical_or(m_sust<(np.mean(m_sust)-3*np.std(m_sust)),m_sust>(np.mean(m_sust)+3*np.std(m_sust)))\n",
    "print(np.sum(m_sust_mask))\n",
    "m_space_mask = np.logical_or(m_space<(np.mean(m_space)-3*np.std(m_space)),m_space>(np.mean(m_space)+3*np.std(m_space)))\n",
    "print(np.sum(m_space_mask))\n",
    "m_sust_mask = np.logical_or(m_sust<(np.mean(m_sust)-3*np.std(m_sust)),m_sust>(np.mean(m_sust)+3*np.std(m_sust)))\n",
    "print(np.sum(m_sust_mask))\n",
    "m_space_mask = np.logical_or(m_space<(np.mean(m_space)-3*np.std(m_space)),m_space>(np.mean(m_space)+3*np.std(m_space)))\n",
    "print(np.sum(m_space_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(12,5))\n",
    "\n",
    "# a = .25\n",
    "# ax[0].scatter(resperr_wm_mean,resperr_ltm_mean,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "# pfit= np.polyfit(resperr_wm_mean,resperr_ltm_mean,1)\n",
    "# x = [np.min(resperr_wm_mean),np.max(resperr_wm_mean)]\n",
    "# y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "# ax[0].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[0],xlim=[0,50],ylim=[0,100],\n",
    "#               xt=[0,25,50],xtl=[0,25,50],\n",
    "#               yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "#               xl=\"Working memory\",yl=\"Long-term memory\")\n",
    "\n",
    "#ax[1].lmplot(m_sust,resperr_ltm_mean)\n",
    "ax[0].scatter(m_sust,resperr_ltm_mean,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_sust,resperr_ltm_mean,1)\n",
    "x = [np.min(m_sust),np.max(m_sust)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[0].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[0],xlim=[-5,10],ylim=[0,100],\n",
    "              xt=[-5,0,5,10],xtl=[-5,0,5,10],\n",
    "              yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "              xl=\"Sustained attention\",yl=\"Long-term memory\")\n",
    "\n",
    "ax[1].scatter(m_space,resperr_ltm_mean,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_space,resperr_ltm_mean,1)\n",
    "x = [np.min(m_space),np.max(m_space)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[1].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[1],xlim=[-.05,.1],ylim=[0,100],\n",
    "              xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "              yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "              xl=\"Spatial attention\",yl=\"Long-term memory\")\n",
    "\n",
    "\n",
    "ax[2].scatter(m_space,m_sust,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_space,m_sust,1)\n",
    "x = [np.min(m_space),np.max(m_space)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[2].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[2],xlim=[-.05,.1],ylim=[-5,10],\n",
    "             xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "             yt=[-5,0,5,10],ytl=[-5,0,5,10],\n",
    "             xl=\"Spatial attention\",yl=\"Sustained attention\")\n",
    "\n",
    "plt.subplots_adjust(wspace=.75)\n",
    "plt.subplots_adjust(hspace=.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.zscore(m_sust[:nsubj_1a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscoring per expt\n",
    "m_sust_z = np.zeros((nsubj))\n",
    "m_space_z = np.zeros((nsubj))\n",
    "resperr_wm_mean_z = np.zeros((nsubj))\n",
    "resperr_ltm_mean_z = np.zeros((nsubj))\n",
    "\n",
    "#expt1a\n",
    "m_sust_z[:nsubj_1a] = scipy.stats.zscore(m_sust[:nsubj_1a])\n",
    "m_space_z[:nsubj_1a] = scipy.stats.zscore(m_space[:nsubj_1a])\n",
    "resperr_wm_mean_z[:nsubj_1a] = scipy.stats.zscore(resperr_wm_mean[:nsubj_1a])\n",
    "resperr_ltm_mean_z[:nsubj_1a] = scipy.stats.zscore(resperr_ltm_mean[:nsubj_1a])\n",
    "\n",
    "#expt1b\n",
    "n = nsubj_1a\n",
    "m_sust_z[n:(n+nsubj_1b)] = scipy.stats.zscore(m_sust[n:(n+nsubj_1b)])\n",
    "m_space_z[n:(n+nsubj_1b)] = scipy.stats.zscore(m_space[n:(n+nsubj_1b)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_1b)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_1b)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_1b)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_1b)])\n",
    "                                                     \n",
    "#expt2\n",
    "n = nsubj_1a+nsubj_1b\n",
    "m_sust_z[n:(n+nsubj_2)] = scipy.stats.zscore(m_sust[n:(n+nsubj_2)])\n",
    "m_space_z[n:(n+nsubj_2)] = scipy.stats.zscore(m_space[n:(n+nsubj_2)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_2)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_2)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_2)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_2)])\n",
    "\n",
    "#expt3a\n",
    "n = nsubj_1a+nsubj_1b+nsubj_2\n",
    "m_sust_z[n:(n+nsubj_3a)] = scipy.stats.zscore(m_sust[n:(n+nsubj_3a)])\n",
    "m_space_z[n:(n+nsubj_3a)] = scipy.stats.zscore(m_space[n:(n+nsubj_3a)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_3a)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_1b)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_3a)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_1b)])\n",
    "\n",
    "#expt2\n",
    "n = nsubj_1a+nsubj_1b+nsubj_2+nsubj_3a\n",
    "m_sust_z[n:(n+nsubj_3b)] = scipy.stats.zscore(m_sust[n:(n+nsubj_3b)])\n",
    "m_space_z[n:(n+nsubj_3b)] = scipy.stats.zscore(m_space[n:(n+nsubj_3b)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_3b)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_3b)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_3b)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_3b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(resperr_ltm_mean))\n",
    "print(np.mean(resperr_ltm_mean_z))\n",
    "print(np.min(resperr_ltm_mean))\n",
    "print(np.min(resperr_ltm_mean_z))\n",
    "print(np.max(resperr_ltm_mean))\n",
    "print(np.max(resperr_ltm_mean_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(12,5))\n",
    "\n",
    "# a = .25\n",
    "# ax[0].scatter(resperr_wm_mean,resperr_ltm_mean,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "# pfit= np.polyfit(resperr_wm_mean,resperr_ltm_mean,1)\n",
    "# x = [np.min(resperr_wm_mean),np.max(resperr_wm_mean)]\n",
    "# y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "# ax[0].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[0],xlim=[0,50],ylim=[0,100],\n",
    "#               xt=[0,25,50],xtl=[0,25,50],\n",
    "#               yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "#               xl=\"Working memory\",yl=\"Long-term memory\")\n",
    "\n",
    "#ax[1].lmplot(m_sust,resperr_ltm_mean)\n",
    "ax[0].scatter(m_sust_z,resperr_ltm_mean_z,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_sust_z,resperr_ltm_mean_z,1)\n",
    "x = [np.min(m_sust_z),np.max(m_sust_z)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[0].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[0],xlim=[-5,10],ylim=[0,100],\n",
    "#               xt=[-5,0,5,10],xtl=[-5,0,5,10],\n",
    "#               yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "#               xl=\"Sustained attention\",yl=\"Long-term memory\")\n",
    "\n",
    "ax[1].scatter(m_space_z,resperr_ltm_mean_z,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_space_z,resperr_ltm_mean_z,1)\n",
    "x = [np.min(m_space_z),np.max(m_space_z)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[1].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[1],xlim=[-.05,.1],ylim=[0,100],\n",
    "#               xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "#               yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "#               xl=\"Spatial attention\",yl=\"Long-term memory\")\n",
    "\n",
    "\n",
    "ax[2].scatter(m_space_z,m_sust_z,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_space_z,m_sust_z,1)\n",
    "x = [np.min(m_space_z),np.max(m_space_z)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[2].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[2],xlim=[-.05,.1],ylim=[-5,10],\n",
    "#              xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "#              yt=[-5,0,5,10],ytl=[-5,0,5,10],\n",
    "#              xl=\"Spatial attention\",yl=\"Sustained attention\")\n",
    "\n",
    "plt.subplots_adjust(wspace=.75)\n",
    "plt.subplots_adjust(hspace=.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working memory and long-term memory, overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(resperr_wm_mean)\n",
    "Y = resperr_ltm_mean \n",
    "\n",
    "model = sm.OLS(Y, X).fit() \n",
    "\n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sustained attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust[:,np.newaxis])\n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust_z[:,np.newaxis])\n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust_cued[:,np.newaxis])\n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust_uncued[:,np.newaxis])\n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_space[:,np.newaxis])\n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_space_z[:,np.newaxis])\n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between sustained and spatial attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(m_sust,m_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(m_sust_z,m_space_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using both sustained and spatial attention as predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(m_sust[:,np.newaxis],m_space[:,np.newaxis],axis=1)\n",
    "X = sm.add_constant(X) \n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "print(\"beta\", np.round(model.params[1:],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1,2]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(m_sust_z[:,np.newaxis],m_space_z[:,np.newaxis],axis=1)\n",
    "X = sm.add_constant(X) \n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "print(\"beta\", np.round(model.params[1:],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1,2]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CSV for R \n",
    "\n",
    "While the modeling results above were computed in python, it obtains the same results as in R. To run the full analyses in R I outputted the data as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(np.append(np.append(np.append(m_space[:,np.newaxis],m_sust[:,np.newaxis],axis=1),resperr_ltm_mean[:,np.newaxis],axis=1),resperr_wm_mean[:,np.newaxis],axis=1),\n",
    "                         columns=['spatial','sustained','resperr_ltm','resperr_wm'])\n",
    "#df.to_csv('./../results/expt123_individdifferences.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(np.append(np.append(np.append(m_space_z[:,np.newaxis],m_sust_z[:,np.newaxis],axis=1),resperr_ltm_mean[:,np.newaxis],axis=1),resperr_wm_mean[:,np.newaxis],axis=1),\n",
    "                         columns=['spatial','sustained','resperr_ltm','resperr_wm'])\n",
    "#df.to_csv('./../results/expt123_individdifferences_z.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(m_sust_cued,m_sust_uncued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(np.append(np.append(np.append(np.append(m_space[:,np.newaxis],m_sust_cued[:,np.newaxis],axis=1),m_sust_uncued[:,np.newaxis],axis=1),resperr_ltm_mean[:,np.newaxis],axis=1),resperr_wm_mean[:,np.newaxis],axis=1),\n",
    "                         columns=['spatial','sustained_cued','sustained_uncued','resperr_ltm','resperr_wm'])\n",
    "#df.to_csv('./../results/expt123_individdifferences_cueduncued.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZSCORING HIGHER-LEVEL EXPERIMENT FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscoring per expt\n",
    "m_sust_z = np.zeros((nsubj))\n",
    "m_space_z = np.zeros((nsubj))\n",
    "resperr_wm_mean_z = np.zeros((nsubj))\n",
    "resperr_ltm_mean_z = np.zeros((nsubj))\n",
    "\n",
    "#expt1\n",
    "m_sust_z[:(nsubj_1a+nsubj_1b)] = scipy.stats.zscore(m_sust[:(nsubj_1a+nsubj_1b)])\n",
    "m_space_z[:(nsubj_1a+nsubj_1b)] = scipy.stats.zscore(m_space[:(nsubj_1a+nsubj_1b)])\n",
    "resperr_wm_mean_z[:(nsubj_1a+nsubj_1b)] = scipy.stats.zscore(resperr_wm_mean[:(nsubj_1a+nsubj_1b)])\n",
    "resperr_ltm_mean_z[:(nsubj_1a+nsubj_1b)] = scipy.stats.zscore(resperr_ltm_mean[:(nsubj_1a+nsubj_1b)])\n",
    "                                                     \n",
    "#expt2\n",
    "n = nsubj_1a+nsubj_1b\n",
    "m_sust_z[n:(n+nsubj_2)] = scipy.stats.zscore(m_sust[n:(n+nsubj_2)])\n",
    "m_space_z[n:(n+nsubj_2)] = scipy.stats.zscore(m_space[n:(n+nsubj_2)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_2)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_2)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_2)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_2)])\n",
    "\n",
    "#expt3\n",
    "n = nsubj_1a+nsubj_1b+nsubj_2\n",
    "m_sust_z[n:(n+nsubj_3a+nsubj_3b)] = scipy.stats.zscore(m_sust[n:(n+nsubj_3a+nsubj_3b)])\n",
    "m_space_z[n:(n+nsubj_3a+nsubj_3b)] = scipy.stats.zscore(m_space[n:(n+nsubj_3a+nsubj_3b)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_3a+nsubj_3b)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_3a+nsubj_3b)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_3a+nsubj_3b)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_3a+nsubj_3b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust_z[:,np.newaxis])\n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])\n",
    "\n",
    "X = sm.add_constant(m_space_z[:,np.newaxis])\n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])\n",
    "\n",
    "spearmanr(m_sust_z,m_space_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preallocate\n",
    "nits=1000\n",
    "cuedvalidly_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_wm_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_ltm_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "cuedvalidly = []\n",
    "wmdiff = []\n",
    "ltmdiff = []\n",
    "\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    print(isubj)\n",
    "    \n",
    "    #append all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuedvalidly.append(np.zeros(np.sum(trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)))\n",
    "        wmdiff.append(np.zeros(np.sum(trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)))\n",
    "        ltmdiff.append(np.zeros(np.sum(np.logical_and(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuedvalidly.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        wmdiff.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        ltmdiff.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3)),\n",
    "                                         trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = dat_wm[isubj].block==iblock\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        #reorder LTM difference according to wm encoding order\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuedvalidly[isubj][count] =(cuevalid[i])\n",
    "            wmdiff[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    for iit in range(nits):\n",
    "        \n",
    "        nt_downsamp = int(np.floor(np.size(ltmdiff[isubj])*prop_downsamp))\n",
    "        \n",
    "        idx = np.random.permutation(np.size(ltmdiff[isubj]))[:nt_downsamp]\n",
    "        \n",
    "        cuedvalidly_downsamp = cuedvalidly[isubj][idx]\n",
    "        wmdiff_downsamp = wmdiff[isubj][idx]\n",
    "        ltmdiff_downsamp = ltmdiff[isubj][idx]\n",
    "        \n",
    "        temp_perc = (np.percentile(ltmdiff_downsamp,np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "\n",
    "        for i,iperc in enumerate(temp_perc[1:]):\n",
    "            #print(np.sum(np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])))\n",
    "            cuedvalidly_bin_downsamp[isubj,i,iit]=np.mean(cuedvalidly_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_wm_bin_downsamp[isubj,i,iit]=np.mean(wmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_ltm_bin_downsamp[isubj,i,iit]= np.mean(ltmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate\n",
    "nits=1000\n",
    "cuedvalidly_cued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_wm_cued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_ltm_cued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "wmdiff_cued = []\n",
    "ltmdiff_cued = []\n",
    "cuevalid_cued = []\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    print(isubj)\n",
    "    \n",
    "    #append extra zeros for all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuevalid_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        wmdiff_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        ltmdiff_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuevalid_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        wmdiff_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        ltmdiff_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==1),trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==1),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==1)\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==1)\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuevalid_cued[isubj][count] =(cuevalid[i])\n",
    "            wmdiff_cued[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff_cued[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    for iit in range(nits):\n",
    "        \n",
    "        nt_downsamp = int(np.floor(np.size(ltmdiff_cued[isubj])*prop_downsamp))\n",
    "        \n",
    "        idx = np.random.permutation(np.size(ltmdiff_cued[isubj]))[:nt_downsamp]\n",
    "        \n",
    "        cuedvalidly_downsamp = cuevalid_cued[isubj][idx]\n",
    "        wmdiff_downsamp = wmdiff_cued[isubj][idx]\n",
    "        ltmdiff_downsamp = ltmdiff_cued[isubj][idx]\n",
    "        \n",
    "        temp_perc = (np.percentile(ltmdiff_downsamp,np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "\n",
    "        for i,iperc in enumerate(temp_perc[1:]):\n",
    "            #print(np.sum(np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])))\n",
    "            cuedvalidly_cued_bin_downsamp[isubj,i,iit]=np.mean(cuedvalidly_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_wm_cued_bin_downsamp[isubj,i,iit]=np.mean(wmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_ltm_cued_bin_downsamp[isubj,i,iit]= np.mean(ltmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preallocate\n",
    "nits=1000\n",
    "cuedvalidly_uncued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_wm_uncued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_ltm_uncued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "wmdiff_uncued = []\n",
    "ltmdiff_uncued = []\n",
    "cuevalid_uncued = []\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    print(isubj)\n",
    "    \n",
    "    #append extra zeros for all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuevalid_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        wmdiff_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        ltmdiff_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuevalid_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        wmdiff_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        ltmdiff_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==0),trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==3),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==0)\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==3)\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuevalid_uncued[isubj][count] =(cuevalid[i])\n",
    "            wmdiff_uncued[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff_uncued[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    for iit in range(nits):\n",
    "        \n",
    "        nt_downsamp = int(np.floor(np.size(ltmdiff_uncued[isubj])*prop_downsamp))\n",
    "        \n",
    "        idx = np.random.permutation(np.size(ltmdiff_uncued[isubj]))[:nt_downsamp]\n",
    "        \n",
    "        cuedvalidly_downsamp = cuevalid_uncued[isubj][idx]\n",
    "        wmdiff_downsamp = wmdiff_uncued[isubj][idx]\n",
    "        ltmdiff_downsamp = ltmdiff_uncued[isubj][idx]\n",
    "        \n",
    "        temp_perc = (np.percentile(ltmdiff_downsamp,np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "\n",
    "        for i,iperc in enumerate(temp_perc[1:]):\n",
    "            #print(np.sum(np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])))\n",
    "            cuedvalidly_uncued_bin_downsamp[isubj,i,iit]=np.mean(cuedvalidly_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_wm_uncued_bin_downsamp[isubj,i,iit]=np.mean(wmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_ltm_uncued_bin_downsamp[isubj,i,iit]= np.mean(ltmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sust_downsamp = np.zeros((nsubj,nits))\n",
    "m_sust_cued_downsamp = np.zeros((nsubj,nits))\n",
    "m_sust_uncued_downsamp = np.zeros((nsubj,nits))\n",
    "m_space_downsamp = np.zeros((nsubj,nits))\n",
    "for isubj in range(nsubj):\n",
    "    for iit in range(nits):\n",
    "        pfit1 = np.polyfit(np.arange(nbins),resperr_wm_cued_bin_downsamp[isubj,:,iit],1)\n",
    "        pfit2 = np.polyfit(np.arange(nbins),resperr_wm_uncued_bin_downsamp[isubj,:,iit],1)\n",
    "        m_sust_cued_downsamp[isubj,iit] = pfit1[0]\n",
    "        m_sust_uncued_downsamp[isubj,iit] = pfit2[0]\n",
    "        m_sust_downsamp[isubj,iit] = (pfit1[0]+pfit2[0])/2\n",
    "\n",
    "        pfit = np.polyfit(np.arange(nbins),(1-cuedvalidly_bin_downsamp[isubj,:,iit]),1)\n",
    "        m_space_downsamp[isubj,iit] = pfit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(m_space_downsamp))\n",
    "print(bootstrap.ci(np.mean(m_space_downsamp,axis=0)))\n",
    "print(np.sort(np.mean(m_space_downsamp,axis=0))[50])\n",
    "print(np.sort(np.mean(m_space_downsamp,axis=0))[950])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(m_sust_downsamp))\n",
    "print(bootstrap.ci(np.mean(m_sust_downsamp,axis=0)))\n",
    "print(np.sort(np.mean(m_sust_downsamp,axis=0))[50])\n",
    "print(np.sort(np.mean(m_sust_downsamp,axis=0))[950])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_sust_downsamp = np.zeros((nits))\n",
    "for iit in range(nits):\n",
    "    X = sm.add_constant(m_sust_downsamp[:,iit][:,np.newaxis])\n",
    "    Y = resperr_ltm_mean\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    beta_sust_downsamp[iit] = model.params[1:]#,decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1,2]),decimals=2))\n",
    "    #print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "    #print(\"pvalue\", model.pvalues[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(beta_sust_downsamp))\n",
    "print(np.sort(beta_sust_downsamp)[25])\n",
    "print(np.sort(beta_sust_downsamp)[975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_space_downsamp = np.zeros((nits))\n",
    "for iit in range(nits):\n",
    "    X = sm.add_constant(m_space_downsamp[:,iit][:,np.newaxis])\n",
    "    Y = resperr_ltm_mean\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    beta_space_downsamp[iit] = model.params[1:]#,decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1,2]),decimals=2))\n",
    "    #print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "    #print(\"pvalue\", model.pvalues[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-219.36303762017312\n",
      "-297.051367509677\n",
      "-152.70541364508523\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(beta_space_downsamp))\n",
    "print(np.sort(beta_space_downsamp)[25])\n",
    "print(np.sort(beta_space_downsamp)[975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
