{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rc\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import scikits.bootstrap as bootstrap\n",
    "from necessary_analysis_scripts import prettify_plot, bar_witherror_anddots\n",
    "from necessary_analysis_scripts import calculate_aprime, resampling_statistics, test_normality, run_stats\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_1samp\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "import scipy.stats as stats\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot within jupyter notebooks\n",
    "%matplotlib inline \n",
    "\n",
    "#tab completion for files\n",
    "%config IPCompleter.greedy=True \n",
    "\n",
    "#supress scientific notation\n",
    "np.set_printoptions(suppress=True) \n",
    "\n",
    "#font defaults\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "rc('text', usetex=False)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name_1a = 'expt1a'\n",
    "exp_name_1b = 'expt1b'\n",
    "exp_name_2 = 'expt2'\n",
    "exp_name_3a = 'expt3a'\n",
    "exp_name_3b = 'expt3b'\n",
    "\n",
    "#expdir\n",
    "exp_dir_1a = '../../' + exp_name_1a + '/'\n",
    "exp_dir_1b = '../../' + exp_name_1b + '/'\n",
    "exp_dir_2 = '../../' + exp_name_2 + '/'\n",
    "exp_dir_3a = '../../' + exp_name_3a + '/'\n",
    "exp_dir_3b = '../../' + exp_name_3b + '/'\n",
    "\n",
    "#project details\n",
    "nb = 16                     #number of blocks\n",
    "nt_wm_perblock = 24         #number of working memory trials per block\n",
    "nt_ltm_perblock = 60        #number of long-term memory trials per block\n",
    "nt_wm = nb*nt_wm_perblock   #total number of working memory trials\n",
    "nt_ltm = nb*nt_ltm_perblock #total number of long-term memory trials\n",
    "\n",
    "#statistics\n",
    "n_its = 100000              #number of iterations for statistics     \n",
    "\n",
    "#binning analysis\n",
    "nbins = 8\n",
    "prop_downsamp = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "24\n",
      "30\n",
      "24\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "subj_name_1a = ['0419171_rtPreStim01','0419172_rtPreStim01','0421171_rtPreStim01',\n",
    "             '0421172_rtPreStim01','0421173_rtPreStim01','0424171_rtPreStim01',\n",
    "             '0424172_rtPreStim01','0428171_rtPreStim01','0428172_rtPreStim01',\n",
    "             '0501171_rtPreStim01','0501173_rtPreStim01','0503171_rtPreStim01',\n",
    "             '0503172_rtPreStim01','0503173_rtPreStim01','0505171_rtPreStim01',\n",
    "             '0505172_rtPreStim01','0505175_rtPreStim01','0508171_rtPreStim01',\n",
    "             '0508172_rtPreStim01','0508173_rtPreStim01','0515171_rtPreStim01',\n",
    "             '0522171_rtPreStim01','0526171_rtPreStim01']\n",
    "nsubj_1a = np.size(subj_name_1a)\n",
    "print(nsubj_1a)\n",
    "\n",
    "subj_name_1b = ['0809181_rtPreStim08','0809182_rtPreStim08','0810181_rtPreStim08',\n",
    "             '0810182_rtPreStim08','0813181_rtPreStim08','0813182_rtPreStim08',\n",
    "             '0814181_rtPreStim08','0814182_rtPreStim08','0815181_rtPreStim08',\n",
    "             '0815182_rtPreStim08','0815183_rtPreStim08','0815184_rtPreStim08',\n",
    "             '0816182_rtPreStim08','0817181_rtPreStim08','0820181_rtPreStim08',\n",
    "             '0822181_rtPreStim08','0824181_rtPreStim08','0827181_rtPreStim08',\n",
    "             '0827183_rtPreStim08','0827184_rtPreStim08','0827185_rtPreStim08',\n",
    "             '0827186_rtPreStim08','0827187_rtPreStim08','0828181_rtPreStim08']\n",
    "nsubj_1b = np.size(subj_name_1b)\n",
    "print(nsubj_1b)\n",
    "\n",
    "subj_name_2 = ['0626171_rtPreStim02','0627171_rtPreStim02','0628171_rtPreStim02',\n",
    "             '0629171_rtPreStim02','0710171_rtPreStim02','0719171_rtPreStim02',\n",
    "             '0720171_rtPreStim02','0725171_rtPreStim02','0803171_rtPreStim02',\n",
    "             '0809171_rtPreStim02','0816171_rtPreStim02','0821171_rtPreStim02',\n",
    "             '0824171_rtPreStim02','0828171_rtPreStim02','0829171_rtPreStim02',\n",
    "             '0830171_rtPreStim02','0830172_rtPreStim02','0901171_rtPreStim02',\n",
    "             '0904171_rtPreStim02','0906171_rtPreStim02','0907171_rtPreStim02',\n",
    "             '0908171_rtPreStim02','0915171_rtPreStim02','0919171_rtPreStim02',\n",
    "             '0922171_rtPreStim02','1005171_rtPreStim02','1010171_rtPreStim02',\n",
    "             '1011171_rtPreStim02','1013171_rtPreStim02','1102171_rtPreStim02']\n",
    "nsubj_2 = np.size(subj_name_2)\n",
    "print(nsubj_2)\n",
    "\n",
    "subj_name_3a = ['0223181_rtPreStim05','0223182_rtPreStim05','0223183_rtPreStim05',\n",
    "             '0225181_rtPreStim05','0226181_rtPreStim05','0226182_rtPreStim05',\n",
    "             '0227181_rtPreStim05','0227182_rtPreStim05','0227183_rtPreStim05',\n",
    "             '0227184_rtPreStim05','0227185_rtPreStim05','0227186_rtPreStim05',\n",
    "             '0227187_rtPreStim05','0227188_rtPreStim05','0228181_rtPreStim05',\n",
    "             '0228182_rtPreStim05','0301181_rtPreStim05','0301182_rtPreStim05',\n",
    "             '0301183_rtPreStim05','0301184_rtPreStim05','0301185_rtPreStim05',\n",
    "             '0302181_rtPreStim05','0302182_rtPreStim05','0531181_rtPreStim05']\n",
    "\n",
    "nsubj_3a = np.size(subj_name_3a)\n",
    "print(nsubj_3a)\n",
    "\n",
    "subj_name_3b = ['0307181_rtPreStim06','0307182_rtPreStim06','0402181_rtPreStim06',\n",
    "            '0402183_rtPreStim06','0402184_rtPreStim06','0402185_rtPreStim06',\n",
    "            '0402186_rtPreStim06','0402187_rtPreStim06','0402188_rtPreStim06',\n",
    "            '0402189_rtPreStim06','0404181_rtPreStim06','0404182_rtPreStim06',\n",
    "            '0404183_rtPreStim06','0404184_rtPreStim06','0404185_rtPreStim06',\n",
    "            '0404186_rtPreStim06','0404187_rtPreStim06','0404188_rtPreStim06',\n",
    "            '0406181_rtPreStim06','0406182_rtPreStim06','0406183_rtPreStim06',\n",
    "            '0406184_rtPreStim06','0406185_rtPreStim06','0406186_rtPreStim06',\n",
    "            '0406188_rtPreStim06','0406189_rtPreStim06'] #'0406187_rtPreStim06' - CHECK FOR ZEROS\n",
    "nsubj_3b = np.size(subj_name_3b)\n",
    "print(nsubj_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# subjects = 127\n"
     ]
    }
   ],
   "source": [
    "#load files\n",
    "dat_wm_1a = {}\n",
    "dat_ltm_1a = {}\n",
    "for isubj in range(nsubj_1a):\n",
    "    dat_wm_1a[isubj] = pd.read_csv(exp_dir_1a + subj_name_1a[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_1a[isubj] = pd.read_csv(exp_dir_1a + subj_name_1a[isubj] +'_ltmlog.csv')\n",
    "dat_wm_1b = {}\n",
    "dat_ltm_1b = {}\n",
    "for isubj in range(nsubj_1b):\n",
    "    dat_wm_1b[isubj] = pd.read_csv(exp_dir_1b + subj_name_1b[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_1b[isubj] = pd.read_csv(exp_dir_1b + subj_name_1b[isubj] +'_ltmlog.csv')\n",
    "dat_wm_2 = {}\n",
    "dat_ltm_2 = {}\n",
    "for isubj in range(nsubj_2):\n",
    "    dat_wm_2[isubj] = pd.read_csv(exp_dir_2 + subj_name_2[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_2[isubj] = pd.read_csv(exp_dir_2 + subj_name_2[isubj] +'_ltmlog.csv')\n",
    "dat_wm_3a = {}\n",
    "dat_ltm_3a = {}\n",
    "for isubj in range(nsubj_3a):\n",
    "    dat_wm_3a[isubj] = pd.read_csv(exp_dir_3a + subj_name_3a[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_3a[isubj] = pd.read_csv(exp_dir_3a + subj_name_3a[isubj] +'_ltmlog.csv')\n",
    "dat_wm_3b = {}\n",
    "dat_ltm_3b = {}\n",
    "for isubj in range(nsubj_3b):\n",
    "    dat_wm_3b[isubj] = pd.read_csv(exp_dir_3b + subj_name_3b[isubj] +'_wmlog.csv')\n",
    "    dat_ltm_3b[isubj] = pd.read_csv(exp_dir_3b + subj_name_3b[isubj] +'_ltmlog.csv')\n",
    "\n",
    "nsubj = nsubj_1a+nsubj_1b+nsubj_2+nsubj_3a+nsubj_3b\n",
    "print('# subjects = %d' %(nsubj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append\n",
    "dat_wm = {}\n",
    "dat_ltm = {}\n",
    "for isubj in range(nsubj):\n",
    "    if isubj<nsubj_1a:\n",
    "        dat_wm[isubj] = dat_wm_1a[isubj]\n",
    "        dat_ltm[isubj] = dat_ltm_1a[isubj]\n",
    "    elif isubj<(nsubj_1a+nsubj_1b):\n",
    "        dat_wm[isubj] = dat_wm_1b[isubj-nsubj_1a]\n",
    "        dat_ltm[isubj] = dat_ltm_1b[isubj-nsubj_1a]\n",
    "    elif isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "        dat_wm[isubj] = dat_wm_2[isubj-nsubj_1a-nsubj_1b]\n",
    "        dat_ltm[isubj] = dat_ltm_2[isubj-nsubj_1a-nsubj_1b]\n",
    "    elif isubj<(nsubj_1a+nsubj_1b+nsubj_2+nsubj_3a):\n",
    "        dat_wm[isubj] = dat_wm_3a[isubj-nsubj_1a-nsubj_1b-nsubj_2]\n",
    "        dat_ltm[isubj] = dat_ltm_3a[isubj-nsubj_1a-nsubj_1b-nsubj_2]\n",
    "    else:\n",
    "        dat_wm[isubj] = dat_wm_3b[isubj-nsubj_1a-nsubj_1b-nsubj_2-nsubj_3a]\n",
    "        dat_ltm[isubj] = dat_ltm_3b[isubj-nsubj_1a-nsubj_1b-nsubj_2-nsubj_3a] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0 completed 88%\t337 trials\n",
      "S1 completed 87%\t333 trials\n",
      "S2 completed 82%\t315 trials\n",
      "S3 completed 75%\t287 trials\n",
      "S4 completed 62%\t239 trials\n",
      "S5 completed 96%\t367 trials\n",
      "S6 completed 79%\t302 trials\n",
      "S7 completed 51%\t196 trials\n",
      "S8 completed 78%\t298 trials\n",
      "S9 completed 71%\t274 trials\n",
      "S10 completed 81%\t312 trials\n",
      "S11 completed 59%\t228 trials\n"
     ]
    }
   ],
   "source": [
    "proj_dir = '/Volumes/Megabyte/rtPreStim02/'\n",
    "\n",
    "#initialize all trials as 1 (meaning no artifacts)\n",
    "trialorder_wm_noarf = np.ones((nsubj_2,nt_wm)) \n",
    "trialorder_ltm_noarf = np.ones((nsubj_2,nt_ltm))\n",
    "\n",
    "for isubj in range(nsubj_2):\n",
    "    dir_eeg = proj_dir + 'subjects/' + subj_name_2[isubj] + '/data/eeg/'\n",
    "    if os.path.isfile(dir_eeg + subj_name_2[isubj] + '_EEG_SEG_CLEAN.mat'):\n",
    "        mat_contents = sio.loadmat(dir_eeg + subj_name_2[isubj] + '_EEG_SEG_CLEAN.mat',struct_as_record=False,squeeze_me=True)\n",
    "        erp = mat_contents['erp']\n",
    "        idx_eeg_arf = np.where(erp.arf.artifactIndCleaned==1)[0]\n",
    "        idx_noeeg_arf = np.where(erp.arf.artifactIndCleaned==0)[0]\n",
    "        n_trials_noarf = np.size(idx_noeeg_arf)\n",
    "        trialorder_wm_noarf[isubj,idx_eeg_arf] = 0\n",
    "    else:\n",
    "        print('ERROR: no file exists for subject: ', subj_name[isubj])\n",
    "        \n",
    "    print(\"S%i completed %d%%\\t%d trials\" %(isubj, np.round((np.sum(trialorder_wm_noarf[isubj]))/float(nt_wm),decimals=2)*100, np.sum(trialorder_wm_noarf[isubj])))\n",
    "\n",
    "print(\"Avg completed %f\\t%i-%i\" %(np.mean(np.mean(trialorder_wm_noarf==1,axis=1)*100),np.min(np.mean(trialorder_wm_noarf==1,axis=1))*384,np.max(np.mean(trialorder_wm_noarf==1,axis=1))*384))\n",
    "\n",
    "print(np.mean(np.sum(trialorder_wm_noarf==1,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialorder_ltm_noarf = np.zeros((nsubj_2,nt_ltm))\n",
    "for isubj in range(nsubj_2):\n",
    "    i = isubj+nsubj_1a+nsubj_1b\n",
    "    for ib in range(nb):\n",
    "        #identify probed ltmrieval trials for this block\n",
    "        itrials_wm_block = np.where(dat_wm[i].block==ib)[0]\n",
    "        itrials_ltm_block = np.where(dat_ltm[i].block==ib)[0]\n",
    "        \n",
    "        itrials_probe = np.where(np.logical_or(dat_ltm[i].ltmTrialsOldValidCued[itrials_ltm_block]==1,\n",
    "                                               dat_ltm[i].ltmTrialsOldInvalidTested[itrials_ltm_block]==1))[0]\n",
    "        itrials_cuedbutunprobed = np.where(dat_ltm[i].ltmTrialsOldInvalidCued[itrials_ltm_block]==1)[0]\n",
    "\n",
    "        #identify the wm trials for this block\n",
    "        #itrials_wm = ib*nt_wm_perblock+np.arange(nt_wm_perblock)\n",
    "        itrials_ltm = ib*nt_ltm_perblock+np.arange(nt_ltm_perblock)\n",
    "        \n",
    "        #identify the artifacts for this block, based on encoding\n",
    "        ib_wm_arf = trialorder_wm_noarf[isubj][itrials_wm_block]\n",
    "        \n",
    "        #loop through all trials in this block\n",
    "        temp_vec = np.zeros(24)\n",
    "        temp_vec_ltm = np.zeros(60)\n",
    "        temp_vec_ltm[:] = np.nan\n",
    "        for it in range(nt_wm_perblock):\n",
    "            \n",
    "            #identify the ltm trial for this wm trial in this block\n",
    "            it_ltm_wm = np.where(np.ravel(dat_ltm[i].ltmWMtrialNum[itrials_ltm_block]==it))[0]\n",
    "            temp_vec_ltm[it_ltm_wm] = ib_wm_arf[it]\n",
    "            #if np.size(it_ltm_wm)==1:\n",
    "            #    temp_vec_ltm[it_ltm_wm] = ib_wm_arf[it]\n",
    "            #else:\n",
    "            #    temp_vec_ltm[]\n",
    "            #if np.ravel(dat_wm[isubj].cuevalid[itrials_wm_block])[it]==0:\n",
    "            #    it_ltm_wm = np.where(np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm_block])[itrials_cuedbutunprobed]==it)[0]\n",
    "            #    temp_vec_ltm[it_ltm_wm] = (ib_wm_arf[it]==1)*1\n",
    "        trialorder_ltm_noarf[isubj][itrials_ltm] = temp_vec_ltm\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean wm and ltm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate empty matrices\n",
    "resperr_wm_all = []\n",
    "resperr_ltm_all = []\n",
    "resperr_wm_mean = np.empty(nsubj)\n",
    "resperr_ltm_mean = np.empty(nsubj)\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "   \n",
    "    #wm\n",
    "    if isubj<(nsubj_1a+nsubj_1b):\n",
    "        resperr_wm = dat_wm[isubj]['wmresptestimgdiff']\n",
    "    elif isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "        resperr_wm = dat_wm[isubj]['wmresptestimgdiff'][trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1]\n",
    "    else:\n",
    "        resperr_wm = dat_wm[isubj]['wmresptestcolordiff']\n",
    "    resperr_wm_mean[isubj] = np.mean(np.abs(resperr_wm))\n",
    "    \n",
    "    #ltm\n",
    "    if isubj<(nsubj_1a+nsubj_1b):\n",
    "        resperr_ltm = dat_ltm[isubj]['ltmresptestimgdiff'][np.logical_or(dat_ltm[isubj]['ltmTrialsOldValidCued']==1,\n",
    "                                                                   dat_ltm[isubj]['ltmTrialsOldInvalidTested']==1)]\n",
    "    elif isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "        resperr_ltm = dat_ltm[isubj]['ltmresptestimgdiff'][np.logical_and(np.logical_or(dat_ltm[isubj]['ltmTrialsOldValidCued']==1,\n",
    "                                                                   dat_ltm[isubj]['ltmTrialsOldInvalidTested']==1),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)]\n",
    "\n",
    "    else:\n",
    "        resperr_ltm = dat_ltm[isubj]['ltmresptestimgdiff'][np.logical_or(dat_ltm[isubj]['ltmTrialsOldValidCued']==1,\n",
    "                                                                   dat_ltm[isubj]['ltmTrialsOldInvalidTested']==1)]\n",
    "\n",
    "    resperr_ltm_mean[isubj] = np.mean(np.abs(resperr_ltm))\n",
    "\n",
    "#statistics\n",
    "\n",
    "#confidence interval\n",
    "resperr_wm_CIs = bootstrap.ci(data=(resperr_wm_mean), statfunction=scipy.mean,n_samples=n_its)\n",
    "resperr_ltm_CIs = bootstrap.ci(data=(resperr_ltm_mean), statfunction=scipy.mean,n_samples=n_its)\n",
    "\n",
    "#print mean, CIs\n",
    "print(\"Mean response error:\")\n",
    "print(\"wm:\\t\", np.round(np.mean(resperr_wm_mean),decimals=2), np.round(resperr_wm_CIs,decimals=2))\n",
    "print(\"ltm:\\t\", np.round(np.mean(resperr_ltm_mean),decimals=3),np.round(resperr_ltm_CIs,decimals=2))\n",
    "\n",
    "#statistics\n",
    "print('Working memory: cued vs uncued')#wm vs ltm\n",
    "run_stats(resperr_ltm_mean,resperr_wm_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning analysis, all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate\n",
    "cuedvalidly_bin = np.zeros((nsubj,nbins))\n",
    "resperr_wm_bin = np.zeros((nsubj,nbins))\n",
    "resperr_ltm_bin = np.zeros((nsubj,nbins))\n",
    "cuedvalidly = []\n",
    "wmdiff = []\n",
    "ltmdiff = []\n",
    "\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    \n",
    "    #append all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuedvalidly.append(np.zeros(np.sum(trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)))\n",
    "        wmdiff.append(np.zeros(np.sum(trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)))\n",
    "        ltmdiff.append(np.zeros(np.sum(np.logical_and(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuedvalidly.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        wmdiff.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        ltmdiff.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3)),\n",
    "                                         trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = dat_wm[isubj].block==iblock\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        #reorder LTM difference according to wm encoding order\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuedvalidly[isubj][count] =(cuevalid[i])\n",
    "            wmdiff[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    temp_perc = (np.percentile(ltmdiff[isubj],np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "    \n",
    "    for i,iperc in enumerate(temp_perc[1:]):\n",
    "        cuedvalidly_bin[isubj,i]=np.mean(cuedvalidly[isubj][np.logical_and(ltmdiff[isubj]<iperc,ltmdiff[isubj]>temp_perc[i])])\n",
    "        resperr_wm_bin[isubj,i]=np.mean(wmdiff[isubj][np.logical_and(ltmdiff[isubj]<iperc,ltmdiff[isubj]>temp_perc[i])])\n",
    "        resperr_ltm_bin[isubj,i]= np.mean(ltmdiff[isubj][np.logical_and(ltmdiff[isubj]<iperc,ltmdiff[isubj]>temp_perc[i])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning analysis, cued items only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate\n",
    "cuedvalidly_cued_bin = np.zeros((nsubj,nbins))\n",
    "resperr_wm_cued_bin = np.zeros((nsubj,nbins))\n",
    "resperr_ltm_cued_bin = np.zeros((nsubj,nbins))\n",
    "wmdiff_cued = []\n",
    "ltmdiff_cued = []\n",
    "cuevalid_cued = []\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    \n",
    "    #append extra zeros for all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuevalid_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        wmdiff_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        ltmdiff_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuevalid_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        wmdiff_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        ltmdiff_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==1),trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==1),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==1)\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==1)\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuevalid_cued[isubj][count] =(cuevalid[i])\n",
    "            wmdiff_cued[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff_cued[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    temp_perc = (np.percentile(ltmdiff_cued[isubj],np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "    \n",
    "    for i,iperc in enumerate(temp_perc[1:]):\n",
    "        cuedvalidly_cued_bin[isubj,i]=np.mean(cuevalid_cued[isubj][np.logical_and(ltmdiff_cued[isubj]<iperc,ltmdiff_cued[isubj]>temp_perc[i])])\n",
    "        resperr_wm_cued_bin[isubj,i]=np.mean(wmdiff_cued[isubj][np.logical_and(ltmdiff_cued[isubj]<iperc,ltmdiff_cued[isubj]>temp_perc[i])])\n",
    "        resperr_ltm_cued_bin[isubj,i]= np.mean(ltmdiff_cued[isubj][np.logical_and(ltmdiff_cued[isubj]<iperc,ltmdiff_cued[isubj]>temp_perc[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning analysis, uncued items only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate\n",
    "cuedvalidly_uncued_bin = np.zeros((nsubj,nbins))\n",
    "resperr_wm_uncued_bin = np.zeros((nsubj,nbins))\n",
    "resperr_ltm_uncued_bin = np.zeros((nsubj,nbins))\n",
    "wmdiff_uncued = []\n",
    "ltmdiff_uncued = []\n",
    "cuevalid_uncued = []\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    \n",
    "    #append extra zeros for all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuevalid_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        wmdiff_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        ltmdiff_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuevalid_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        wmdiff_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        ltmdiff_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==0),trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==3),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==0)\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==3)\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuevalid_uncued[isubj][count] =(cuevalid[i])\n",
    "            wmdiff_uncued[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff_uncued[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    temp_perc = (np.percentile(ltmdiff_uncued[isubj],np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "    \n",
    "    for i,iperc in enumerate(temp_perc[1:]):\n",
    "        cuedvalidly_uncued_bin[isubj,i]=np.mean(cuevalid_uncued[isubj][np.logical_and(ltmdiff_uncued[isubj]<iperc,ltmdiff_uncued[isubj]>temp_perc[i])])\n",
    "        resperr_wm_uncued_bin[isubj,i]=np.mean(wmdiff_uncued[isubj][np.logical_and(ltmdiff_uncued[isubj]<iperc,ltmdiff_uncued[isubj]>temp_perc[i])])\n",
    "        resperr_ltm_uncued_bin[isubj,i]= np.mean(ltmdiff_uncued[isubj][np.logical_and(ltmdiff_uncued[isubj]<iperc,ltmdiff_uncued[isubj]>temp_perc[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate a measure of of the influence of sustained attention and spatial attention for each individual as the slope of each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sust = np.zeros((nsubj))\n",
    "m_sust_cued = np.zeros((nsubj))\n",
    "m_sust_uncued = np.zeros((nsubj))\n",
    "m_space = np.zeros((nsubj))\n",
    "for isubj in range(nsubj):\n",
    "    pfit1 = np.polyfit(np.arange(nbins),resperr_wm_cued_bin[isubj,:],1)\n",
    "    pfit2 = np.polyfit(np.arange(nbins),resperr_wm_uncued_bin[isubj,:],1)\n",
    "    m_sust_cued[isubj] = pfit1[0]\n",
    "    m_sust_uncued[isubj] = pfit2[0]\n",
    "    m_sust[isubj] = (pfit1[0]+pfit2[0])/2\n",
    "    \n",
    "    pfit = np.polyfit(np.arange(nbins),(1-cuedvalidly_bin[isubj,:]),1)\n",
    "    m_space[isubj] = pfit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats_for_ci_plot(x,y):\n",
    "    p, cov = np.polyfit(x, y, 1, cov=True)                     # parameters and covariance from of the fit of 1-D polynom.\n",
    "    y_model = np.polyval(p, x)                                   # model using the fit parameters; NOTE: parameters here are coefficients\n",
    "\n",
    "    # Statistics\n",
    "    n = y.size                                           # number of observations\n",
    "    m = p.size                                                 # number of parameters\n",
    "    dof = n - m                                                # degrees of freedom\n",
    "    t = stats.t.ppf(0.975, n - m)                              # used for CI and PI bands\n",
    "\n",
    "    # Estimates of Error in Data/Model\n",
    "    resid = y - y_model                           \n",
    "    chi2 = np.sum((resid / y_model)**2)                        # chi-squared; estimates error in data\n",
    "    chi2_red = chi2 / dof                                      # reduced chi-squared; measures goodness of fit\n",
    "    s_err = np.sqrt(np.sum(resid**2) / dof)                    # standard deviation of the error\n",
    "\n",
    "    x2 = np.linspace(np.min(x), np.max(x), 100)\n",
    "    y2 = equation(p, x2)\n",
    "\n",
    "    return t,s_err,n,x2,y2\n",
    "\n",
    "def plot_ci_manual(t, s_err, n, x, x2, y2, ax=None):\n",
    "    \"\"\"Return an axes of confidence bands using a simple approach.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    .. math:: \\left| \\: \\hat{\\mu}_{y|x0} - \\mu_{y|x0} \\: \\right| \\; \\leq \\; T_{n-2}^{.975} \\; \\hat{\\sigma} \\; \\sqrt{\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}}\n",
    "    .. math:: \\hat{\\sigma} = \\sqrt{\\sum_{i=1}^n{\\frac{(y_i-\\hat{y})^2}{n-2}}}\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Duarte.  \"Curve fitting,\" Jupyter Notebook.\n",
    "       http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/CurveFitting.ipynb\n",
    "\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ci = t * s_err * np.sqrt(1/n + (x2 - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "    ax.fill_between(x2, y2 + ci, y2 - ci, facecolor=\"k\", edgecolor=\"None\",alpha=.25)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(20,5.5))\n",
    "\n",
    "a=.1\n",
    "s=200\n",
    "\n",
    "x=m_sust\n",
    "y=resperr_ltm_mean\n",
    "ax[0].scatter(x,y,s=s,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "t,s_err,n,x2,y2 = calculate_stats_for_ci_plot(x,y)\n",
    "plot_ci_manual(t,s_err,n,x,x2,y2,ax=ax[0])\n",
    "#plot_ci_bootstrap(x, y, resid, ax=ax[0])\n",
    "pfit= np.polyfit(m_sust,resperr_ltm_mean,1)\n",
    "x = [np.min(m_sust),np.max(m_sust)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[0].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[0],xlim=[-5,10],ylim=[0,100],\n",
    "              xt=[-5,0,5,10],xtl=[-5,0,5,10],\n",
    "              yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "              xl=\"Sustained attention\",yl=\"Long-term memory\")\n",
    "\n",
    "\n",
    "\n",
    "x=m_space\n",
    "y=resperr_ltm_mean\n",
    "ax[1].scatter(x,y,s=s,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "t,s_err,n,x2,y2 = calculate_stats_for_ci_plot(x,y)\n",
    "plot_ci_manual(t,s_err,n,x,x2,y2,ax=ax[1])\n",
    "pfit= np.polyfit(m_space,resperr_ltm_mean,1)\n",
    "x = [np.min(m_space),np.max(m_space)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[1].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[1],xlim=[-.05,.1],ylim=[0,100],\n",
    "              xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "              yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "              xl=\"Spatial attention\",yl=\"Long-term memory\")\n",
    "\n",
    "x=m_space\n",
    "y=m_sust\n",
    "ax[2].scatter(x,y,s=s,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "t,s_err,n,x2,y2 = calculate_stats_for_ci_plot(x,y)\n",
    "plot_ci_manual(t,s_err,n,x,x2,y2,ax=ax[2])\n",
    "pfit= np.polyfit(m_space,m_sust,1)\n",
    "x = [np.min(m_space),np.max(m_space)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[2].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[2],xlim=[-.05,.1],ylim=[-5,10],\n",
    "             xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "             yt=[-5,0,5,10],ytl=[-5,0,5,10],\n",
    "             xl=\"Spatial attention\",yl=\"Sustained attention\")\n",
    "\n",
    "#plt.axis('scaled')\n",
    "#ax[0].set_aspect('scaled', adjustable='box')\n",
    "plt.subplots_adjust(wspace=.8)\n",
    "plt.subplots_adjust(hspace=.8)\n",
    "\n",
    "#fig_dir = fig_dir = '/Users/megan/Dropbox/conferences/202011_psych/figures/'\n",
    "#fig.savefig(fig_dir + 'figure6_individidff_scatterall_fit_example_1MdB.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spearmanr(m_sust,resperr_ltm_mean))\n",
    "print(spearmanr(m_space,resperr_ltm_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sust_mask = np.logical_or(m_sust<(np.mean(m_sust)-3*np.std(m_sust)),m_sust>(np.mean(m_sust)+3*np.std(m_sust)))\n",
    "print(np.sum(m_sust_mask))\n",
    "m_space_mask = np.logical_or(m_space<(np.mean(m_space)-3*np.std(m_space)),m_space>(np.mean(m_space)+3*np.std(m_space)))\n",
    "print(np.sum(m_space_mask))\n",
    "m_sust_mask = np.logical_or(m_sust<(np.mean(m_sust)-3*np.std(m_sust)),m_sust>(np.mean(m_sust)+3*np.std(m_sust)))\n",
    "print(np.sum(m_sust_mask))\n",
    "m_space_mask = np.logical_or(m_space<(np.mean(m_space)-3*np.std(m_space)),m_space>(np.mean(m_space)+3*np.std(m_space)))\n",
    "print(np.sum(m_space_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(12,5))\n",
    "\n",
    "# a = .25\n",
    "# ax[0].scatter(resperr_wm_mean,resperr_ltm_mean,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "# pfit= np.polyfit(resperr_wm_mean,resperr_ltm_mean,1)\n",
    "# x = [np.min(resperr_wm_mean),np.max(resperr_wm_mean)]\n",
    "# y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "# ax[0].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[0],xlim=[0,50],ylim=[0,100],\n",
    "#               xt=[0,25,50],xtl=[0,25,50],\n",
    "#               yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "#               xl=\"Working memory\",yl=\"Long-term memory\")\n",
    "\n",
    "#ax[1].lmplot(m_sust,resperr_ltm_mean)\n",
    "ax[0].scatter(m_sust,resperr_ltm_mean,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_sust,resperr_ltm_mean,1)\n",
    "x = [np.min(m_sust),np.max(m_sust)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[0].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[0],xlim=[-5,10],ylim=[0,100],\n",
    "              xt=[-5,0,5,10],xtl=[-5,0,5,10],\n",
    "              yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "              xl=\"Sustained attention\",yl=\"Long-term memory\")\n",
    "\n",
    "ax[1].scatter(m_space,resperr_ltm_mean,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_space,resperr_ltm_mean,1)\n",
    "x = [np.min(m_space),np.max(m_space)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[1].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[1],xlim=[-.05,.1],ylim=[0,100],\n",
    "              xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "              yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "              xl=\"Spatial attention\",yl=\"Long-term memory\")\n",
    "\n",
    "\n",
    "ax[2].scatter(m_space,m_sust,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_space,m_sust,1)\n",
    "x = [np.min(m_space),np.max(m_space)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[2].plot(x,y,color='k',lw=3)\n",
    "prettify_plot(ax[2],xlim=[-.05,.1],ylim=[-5,10],\n",
    "             xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "             yt=[-5,0,5,10],ytl=[-5,0,5,10],\n",
    "             xl=\"Spatial attention\",yl=\"Sustained attention\")\n",
    "\n",
    "plt.subplots_adjust(wspace=.75)\n",
    "plt.subplots_adjust(hspace=.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.zscore(m_sust[:nsubj_1a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscoring per expt\n",
    "m_sust_z = np.zeros((nsubj))\n",
    "m_space_z = np.zeros((nsubj))\n",
    "resperr_wm_mean_z = np.zeros((nsubj))\n",
    "resperr_ltm_mean_z = np.zeros((nsubj))\n",
    "\n",
    "#expt1a\n",
    "m_sust_z[:nsubj_1a] = scipy.stats.zscore(m_sust[:nsubj_1a])\n",
    "m_space_z[:nsubj_1a] = scipy.stats.zscore(m_space[:nsubj_1a])\n",
    "resperr_wm_mean_z[:nsubj_1a] = scipy.stats.zscore(resperr_wm_mean[:nsubj_1a])\n",
    "resperr_ltm_mean_z[:nsubj_1a] = scipy.stats.zscore(resperr_ltm_mean[:nsubj_1a])\n",
    "\n",
    "#expt1b\n",
    "n = nsubj_1a\n",
    "m_sust_z[n:(n+nsubj_1b)] = scipy.stats.zscore(m_sust[n:(n+nsubj_1b)])\n",
    "m_space_z[n:(n+nsubj_1b)] = scipy.stats.zscore(m_space[n:(n+nsubj_1b)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_1b)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_1b)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_1b)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_1b)])\n",
    "                                                     \n",
    "#expt2\n",
    "n = nsubj_1a+nsubj_1b\n",
    "m_sust_z[n:(n+nsubj_2)] = scipy.stats.zscore(m_sust[n:(n+nsubj_2)])\n",
    "m_space_z[n:(n+nsubj_2)] = scipy.stats.zscore(m_space[n:(n+nsubj_2)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_2)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_2)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_2)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_2)])\n",
    "\n",
    "#expt3a\n",
    "n = nsubj_1a+nsubj_1b+nsubj_2\n",
    "m_sust_z[n:(n+nsubj_3a)] = scipy.stats.zscore(m_sust[n:(n+nsubj_3a)])\n",
    "m_space_z[n:(n+nsubj_3a)] = scipy.stats.zscore(m_space[n:(n+nsubj_3a)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_3a)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_1b)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_3a)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_1b)])\n",
    "\n",
    "#expt2\n",
    "n = nsubj_1a+nsubj_1b+nsubj_2+nsubj_3a\n",
    "m_sust_z[n:(n+nsubj_3b)] = scipy.stats.zscore(m_sust[n:(n+nsubj_3b)])\n",
    "m_space_z[n:(n+nsubj_3b)] = scipy.stats.zscore(m_space[n:(n+nsubj_3b)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_3b)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_3b)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_3b)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_3b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(resperr_ltm_mean))\n",
    "print(np.mean(resperr_ltm_mean_z))\n",
    "print(np.min(resperr_ltm_mean))\n",
    "print(np.min(resperr_ltm_mean_z))\n",
    "print(np.max(resperr_ltm_mean))\n",
    "print(np.max(resperr_ltm_mean_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(12,5))\n",
    "\n",
    "# a = .25\n",
    "# ax[0].scatter(resperr_wm_mean,resperr_ltm_mean,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "# pfit= np.polyfit(resperr_wm_mean,resperr_ltm_mean,1)\n",
    "# x = [np.min(resperr_wm_mean),np.max(resperr_wm_mean)]\n",
    "# y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "# ax[0].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[0],xlim=[0,50],ylim=[0,100],\n",
    "#               xt=[0,25,50],xtl=[0,25,50],\n",
    "#               yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "#               xl=\"Working memory\",yl=\"Long-term memory\")\n",
    "\n",
    "#ax[1].lmplot(m_sust,resperr_ltm_mean)\n",
    "ax[0].scatter(m_sust_z,resperr_ltm_mean_z,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_sust_z,resperr_ltm_mean_z,1)\n",
    "x = [np.min(m_sust_z),np.max(m_sust_z)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[0].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[0],xlim=[-5,10],ylim=[0,100],\n",
    "#               xt=[-5,0,5,10],xtl=[-5,0,5,10],\n",
    "#               yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "#               xl=\"Sustained attention\",yl=\"Long-term memory\")\n",
    "\n",
    "ax[1].scatter(m_space_z,resperr_ltm_mean_z,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_space_z,resperr_ltm_mean_z,1)\n",
    "x = [np.min(m_space_z),np.max(m_space_z)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[1].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[1],xlim=[-.05,.1],ylim=[0,100],\n",
    "#               xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "#               yt=[0,25,50,75,100],ytl=[0,25,50,75,100],\n",
    "#               xl=\"Spatial attention\",yl=\"Long-term memory\")\n",
    "\n",
    "\n",
    "ax[2].scatter(m_space_z,m_sust_z,s=50,color='k',edgecolor='None',alpha=a,clip_on=False)\n",
    "pfit= np.polyfit(m_space_z,m_sust_z,1)\n",
    "x = [np.min(m_space_z),np.max(m_space_z)]\n",
    "y = [x[0]*pfit[0]+pfit[1],x[1]*pfit[0]+pfit[1]]\n",
    "ax[2].plot(x,y,color='k',lw=3)\n",
    "# prettify_plot(ax[2],xlim=[-.05,.1],ylim=[-5,10],\n",
    "#              xt=[-.1,-.05,0,.05,.1],xtl=[-.1,-.05,0,.05,.1],\n",
    "#              yt=[-5,0,5,10],ytl=[-5,0,5,10],\n",
    "#              xl=\"Spatial attention\",yl=\"Sustained attention\")\n",
    "\n",
    "plt.subplots_adjust(wspace=.75)\n",
    "plt.subplots_adjust(hspace=.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working memory and long-term memory, overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(resperr_wm_mean)\n",
    "Y = resperr_ltm_mean \n",
    "\n",
    "model = sm.OLS(Y, X).fit() \n",
    "\n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sustained attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust[:,np.newaxis])\n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust_z[:,np.newaxis])\n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust_cued[:,np.newaxis])\n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust_uncued[:,np.newaxis])\n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_space[:,np.newaxis])\n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_space_z[:,np.newaxis])\n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between sustained and spatial attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(m_sust,m_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(m_sust_z,m_space_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using both sustained and spatial attention as predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(m_sust[:,np.newaxis],m_space[:,np.newaxis],axis=1)\n",
    "X = sm.add_constant(X) \n",
    "Y = resperr_ltm_mean\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "print(\"beta\", np.round(model.params[1:],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1,2]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(m_sust_z[:,np.newaxis],m_space_z[:,np.newaxis],axis=1)\n",
    "X = sm.add_constant(X) \n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "print(\"beta\", np.round(model.params[1:],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1,2]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CSV for R \n",
    "\n",
    "While the modeling results above were computed in python, it obtains the same results as in R. To run the full analyses in R I outputted the data as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(np.append(np.append(np.append(m_space[:,np.newaxis],m_sust[:,np.newaxis],axis=1),resperr_ltm_mean[:,np.newaxis],axis=1),resperr_wm_mean[:,np.newaxis],axis=1),\n",
    "                         columns=['spatial','sustained','resperr_ltm','resperr_wm'])\n",
    "#df.to_csv('./../results/expt123_individdifferences.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(np.append(np.append(np.append(m_space_z[:,np.newaxis],m_sust_z[:,np.newaxis],axis=1),resperr_ltm_mean[:,np.newaxis],axis=1),resperr_wm_mean[:,np.newaxis],axis=1),\n",
    "                         columns=['spatial','sustained','resperr_ltm','resperr_wm'])\n",
    "#df.to_csv('./../results/expt123_individdifferences_z.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(m_sust_cued,m_sust_uncued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(np.append(np.append(np.append(np.append(m_space[:,np.newaxis],m_sust_cued[:,np.newaxis],axis=1),m_sust_uncued[:,np.newaxis],axis=1),resperr_ltm_mean[:,np.newaxis],axis=1),resperr_wm_mean[:,np.newaxis],axis=1),\n",
    "                         columns=['spatial','sustained_cued','sustained_uncued','resperr_ltm','resperr_wm'])\n",
    "#df.to_csv('./../results/expt123_individdifferences_cueduncued.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZSCORING HIGHER-LEVEL EXPERIMENT FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscoring per expt\n",
    "m_sust_z = np.zeros((nsubj))\n",
    "m_space_z = np.zeros((nsubj))\n",
    "resperr_wm_mean_z = np.zeros((nsubj))\n",
    "resperr_ltm_mean_z = np.zeros((nsubj))\n",
    "\n",
    "#expt1\n",
    "m_sust_z[:(nsubj_1a+nsubj_1b)] = scipy.stats.zscore(m_sust[:(nsubj_1a+nsubj_1b)])\n",
    "m_space_z[:(nsubj_1a+nsubj_1b)] = scipy.stats.zscore(m_space[:(nsubj_1a+nsubj_1b)])\n",
    "resperr_wm_mean_z[:(nsubj_1a+nsubj_1b)] = scipy.stats.zscore(resperr_wm_mean[:(nsubj_1a+nsubj_1b)])\n",
    "resperr_ltm_mean_z[:(nsubj_1a+nsubj_1b)] = scipy.stats.zscore(resperr_ltm_mean[:(nsubj_1a+nsubj_1b)])\n",
    "                                                     \n",
    "#expt2\n",
    "n = nsubj_1a+nsubj_1b\n",
    "m_sust_z[n:(n+nsubj_2)] = scipy.stats.zscore(m_sust[n:(n+nsubj_2)])\n",
    "m_space_z[n:(n+nsubj_2)] = scipy.stats.zscore(m_space[n:(n+nsubj_2)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_2)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_2)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_2)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_2)])\n",
    "\n",
    "#expt3\n",
    "n = nsubj_1a+nsubj_1b+nsubj_2\n",
    "m_sust_z[n:(n+nsubj_3a+nsubj_3b)] = scipy.stats.zscore(m_sust[n:(n+nsubj_3a+nsubj_3b)])\n",
    "m_space_z[n:(n+nsubj_3a+nsubj_3b)] = scipy.stats.zscore(m_space[n:(n+nsubj_3a+nsubj_3b)])\n",
    "resperr_wm_mean_z[n:(n+nsubj_3a+nsubj_3b)] = scipy.stats.zscore(resperr_wm_mean[n:(n+nsubj_3a+nsubj_3b)])\n",
    "resperr_ltm_mean_z[n:(n+nsubj_3a+nsubj_3b)] = scipy.stats.zscore(resperr_ltm_mean[n:(n+nsubj_3a+nsubj_3b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(m_sust_z[:,np.newaxis])\n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])\n",
    "\n",
    "X = sm.add_constant(m_space_z[:,np.newaxis])\n",
    "Y = resperr_ltm_mean_z\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    " \n",
    "print(\"beta\", np.round(model.params[1],decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1]),decimals=2))\n",
    "print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "print(\"pvalue\", model.pvalues[1])\n",
    "\n",
    "spearmanr(m_sust_z,m_space_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preallocate\n",
    "nits=1000\n",
    "cuedvalidly_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_wm_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_ltm_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "cuedvalidly = []\n",
    "wmdiff = []\n",
    "ltmdiff = []\n",
    "\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    print(isubj)\n",
    "    \n",
    "    #append all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuedvalidly.append(np.zeros(np.sum(trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)))\n",
    "        wmdiff.append(np.zeros(np.sum(trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)))\n",
    "        ltmdiff.append(np.zeros(np.sum(np.logical_and(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuedvalidly.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        wmdiff.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        ltmdiff.append(np.zeros(np.sum(np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3)),\n",
    "                                         trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = dat_wm[isubj].block==iblock\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,np.logical_or(dat_ltm[isubj].conditionNum==1,dat_ltm[isubj].conditionNum==3))\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        #reorder LTM difference according to wm encoding order\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuedvalidly[isubj][count] =(cuevalid[i])\n",
    "            wmdiff[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    for iit in range(nits):\n",
    "        \n",
    "        nt_downsamp = int(np.floor(np.size(ltmdiff[isubj])*prop_downsamp))\n",
    "        \n",
    "        idx = np.random.permutation(np.size(ltmdiff[isubj]))[:nt_downsamp]\n",
    "        \n",
    "        cuedvalidly_downsamp = cuedvalidly[isubj][idx]\n",
    "        wmdiff_downsamp = wmdiff[isubj][idx]\n",
    "        ltmdiff_downsamp = ltmdiff[isubj][idx]\n",
    "        \n",
    "        temp_perc = (np.percentile(ltmdiff_downsamp,np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "\n",
    "        for i,iperc in enumerate(temp_perc[1:]):\n",
    "            #print(np.sum(np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])))\n",
    "            cuedvalidly_bin_downsamp[isubj,i,iit]=np.mean(cuedvalidly_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_wm_bin_downsamp[isubj,i,iit]=np.mean(wmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_ltm_bin_downsamp[isubj,i,iit]= np.mean(ltmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate\n",
    "nits=1000\n",
    "cuedvalidly_cued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_wm_cued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_ltm_cued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "wmdiff_cued = []\n",
    "ltmdiff_cued = []\n",
    "cuevalid_cued = []\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    print(isubj)\n",
    "    \n",
    "    #append extra zeros for all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuevalid_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        wmdiff_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        ltmdiff_cued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==1,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuevalid_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        wmdiff_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        ltmdiff_cued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==1)))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==1),trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==1),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==1)\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==1)\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuevalid_cued[isubj][count] =(cuevalid[i])\n",
    "            wmdiff_cued[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff_cued[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    for iit in range(nits):\n",
    "        \n",
    "        nt_downsamp = int(np.floor(np.size(ltmdiff_cued[isubj])*prop_downsamp))\n",
    "        \n",
    "        idx = np.random.permutation(np.size(ltmdiff_cued[isubj]))[:nt_downsamp]\n",
    "        \n",
    "        cuedvalidly_downsamp = cuevalid_cued[isubj][idx]\n",
    "        wmdiff_downsamp = wmdiff_cued[isubj][idx]\n",
    "        ltmdiff_downsamp = ltmdiff_cued[isubj][idx]\n",
    "        \n",
    "        temp_perc = (np.percentile(ltmdiff_downsamp,np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "\n",
    "        for i,iperc in enumerate(temp_perc[1:]):\n",
    "            #print(np.sum(np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])))\n",
    "            cuedvalidly_cued_bin_downsamp[isubj,i,iit]=np.mean(cuedvalidly_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_wm_cued_bin_downsamp[isubj,i,iit]=np.mean(wmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_ltm_cued_bin_downsamp[isubj,i,iit]= np.mean(ltmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preallocate\n",
    "nits=1000\n",
    "cuedvalidly_uncued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_wm_uncued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "resperr_ltm_uncued_bin_downsamp = np.zeros((nsubj,nbins,nits))\n",
    "wmdiff_uncued = []\n",
    "ltmdiff_uncued = []\n",
    "cuevalid_uncued = []\n",
    "\n",
    "for isubj in range(nsubj):\n",
    "    print(isubj)\n",
    "    \n",
    "    #append extra zeros for all trials\n",
    "    if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "        cuevalid_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        wmdiff_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "        ltmdiff_uncued.append(np.zeros(np.sum(np.logical_and(dat_ltm[isubj].conditionNum==3,trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1))))\n",
    "    else:\n",
    "        cuevalid_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        wmdiff_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        ltmdiff_uncued.append(np.zeros(np.sum(dat_ltm[isubj].conditionNum==3)))\n",
    "        \n",
    "    count = 0\n",
    "    for iblock in np.unique(dat_ltm[isubj].block):\n",
    "        #find trials from this block\n",
    "        if np.logical_and(isubj<(nsubj_1a+nsubj_1b+nsubj_2),isubj>=(nsubj_1a+nsubj_1b)):\n",
    "            itrials_wm = np.logical_and(np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==0),trialorder_wm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "            itrials_ltm = np.logical_and(np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==3),trialorder_ltm_noarf[isubj-nsubj_1a-nsubj_1b]==1)\n",
    "        else:\n",
    "            itrials_wm = np.logical_and(dat_wm[isubj].block==iblock,dat_wm[isubj].cuevalid==0)\n",
    "            itrials_ltm = np.logical_and(dat_ltm[isubj].block==iblock,dat_ltm[isubj].conditionNum==3)\n",
    "\n",
    "        #find response error for this block's trials\n",
    "        cuevalid = np.ravel(dat_wm[isubj].cuevalid[itrials_wm])\n",
    "        if isubj<(nsubj_1a+nsubj_1b+nsubj_2):\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestimgdiff[itrials_wm]))\n",
    "        else:\n",
    "            respdiff_wm = np.abs(np.ravel(dat_wm[isubj].wmresptestcolordiff[itrials_wm]))\n",
    "        respdiff_ltm = np.abs(np.ravel(dat_ltm[isubj].ltmresptestimgdiff[itrials_ltm]))\n",
    "        wmtrialnum_wm = np.ravel(dat_wm[isubj].trial[itrials_wm])\n",
    "        wmtrialnum_ltm = np.ravel(dat_ltm[isubj].ltmWMtrialNum[itrials_ltm])\n",
    "\n",
    "        for itrial in range(np.size(wmtrialnum_ltm)):\n",
    "            i = np.where(wmtrialnum_wm==wmtrialnum_ltm[itrial])[0]\n",
    "            cuevalid_uncued[isubj][count] =(cuevalid[i])\n",
    "            wmdiff_uncued[isubj][count] =(respdiff_wm[i])\n",
    "            ltmdiff_uncued[isubj][count]=(respdiff_ltm[itrial])\n",
    "            count=count+1\n",
    "    \n",
    "    #calculate mean response error in the WM phase\n",
    "    for iit in range(nits):\n",
    "        \n",
    "        nt_downsamp = int(np.floor(np.size(ltmdiff_uncued[isubj])*prop_downsamp))\n",
    "        \n",
    "        idx = np.random.permutation(np.size(ltmdiff_uncued[isubj]))[:nt_downsamp]\n",
    "        \n",
    "        cuedvalidly_downsamp = cuevalid_uncued[isubj][idx]\n",
    "        wmdiff_downsamp = wmdiff_uncued[isubj][idx]\n",
    "        ltmdiff_downsamp = ltmdiff_uncued[isubj][idx]\n",
    "        \n",
    "        temp_perc = (np.percentile(ltmdiff_downsamp,np.linspace(0,100,(nbins+1),endpoint=True)))\n",
    "\n",
    "        for i,iperc in enumerate(temp_perc[1:]):\n",
    "            #print(np.sum(np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])))\n",
    "            cuedvalidly_uncued_bin_downsamp[isubj,i,iit]=np.mean(cuedvalidly_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_wm_uncued_bin_downsamp[isubj,i,iit]=np.mean(wmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n",
    "            resperr_ltm_uncued_bin_downsamp[isubj,i,iit]= np.mean(ltmdiff_downsamp[np.logical_and(ltmdiff_downsamp<iperc,ltmdiff_downsamp>temp_perc[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sust_downsamp = np.zeros((nsubj,nits))\n",
    "m_sust_cued_downsamp = np.zeros((nsubj,nits))\n",
    "m_sust_uncued_downsamp = np.zeros((nsubj,nits))\n",
    "m_space_downsamp = np.zeros((nsubj,nits))\n",
    "for isubj in range(nsubj):\n",
    "    for iit in range(nits):\n",
    "        pfit1 = np.polyfit(np.arange(nbins),resperr_wm_cued_bin_downsamp[isubj,:,iit],1)\n",
    "        pfit2 = np.polyfit(np.arange(nbins),resperr_wm_uncued_bin_downsamp[isubj,:,iit],1)\n",
    "        m_sust_cued_downsamp[isubj,iit] = pfit1[0]\n",
    "        m_sust_uncued_downsamp[isubj,iit] = pfit2[0]\n",
    "        m_sust_downsamp[isubj,iit] = (pfit1[0]+pfit2[0])/2\n",
    "\n",
    "        pfit = np.polyfit(np.arange(nbins),(1-cuedvalidly_bin_downsamp[isubj,:,iit]),1)\n",
    "        m_space_downsamp[isubj,iit] = pfit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(m_space_downsamp))\n",
    "print(bootstrap.ci(np.mean(m_space_downsamp,axis=0)))\n",
    "print(np.sort(np.mean(m_space_downsamp,axis=0))[50])\n",
    "print(np.sort(np.mean(m_space_downsamp,axis=0))[950])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(m_sust_downsamp))\n",
    "print(bootstrap.ci(np.mean(m_sust_downsamp,axis=0)))\n",
    "print(np.sort(np.mean(m_sust_downsamp,axis=0))[50])\n",
    "print(np.sort(np.mean(m_sust_downsamp,axis=0))[950])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_sust_downsamp = np.zeros((nits))\n",
    "for iit in range(nits):\n",
    "    X = sm.add_constant(m_sust_downsamp[:,iit][:,np.newaxis])\n",
    "    Y = resperr_ltm_mean\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    beta_sust_downsamp[iit] = model.params[1:]#,decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1,2]),decimals=2))\n",
    "    #print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "    #print(\"pvalue\", model.pvalues[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(beta_sust_downsamp))\n",
    "print(np.sort(beta_sust_downsamp)[25])\n",
    "print(np.sort(beta_sust_downsamp)[975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_space_downsamp = np.zeros((nits))\n",
    "for iit in range(nits):\n",
    "    X = sm.add_constant(m_space_downsamp[:,iit][:,np.newaxis])\n",
    "    Y = resperr_ltm_mean\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    beta_space_downsamp[iit] = model.params[1:]#,decimals=2),np.round(model.conf_int(alpha=0.05, cols=[1,2]),decimals=2))\n",
    "    #print(\"rsquared\", np.round(model.rsquared_adj,decimals=2))\n",
    "    #print(\"pvalue\", model.pvalues[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-219.36303762017312\n",
      "-297.051367509677\n",
      "-152.70541364508523\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(beta_space_downsamp))\n",
    "print(np.sort(beta_space_downsamp)[25])\n",
    "print(np.sort(beta_space_downsamp)[975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
